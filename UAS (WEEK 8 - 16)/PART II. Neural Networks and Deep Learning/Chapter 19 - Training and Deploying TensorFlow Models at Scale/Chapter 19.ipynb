{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7e7e08",
   "metadata": {},
   "source": [
    "### 1. SETUP DAN PERSIAPAN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2dc1cad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:48:23.572487: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750438103.649044  269604 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750438103.670618  269604 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-20 23:48:23.804333: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import shutil\n",
    "import subprocess\n",
    "import requests\n",
    "import time\n",
    "import grpc\n",
    "from tensorflow_serving.apis import prediction_service_pb2_grpc\n",
    "from tensorflow_serving.apis.predict_pb2 import PredictRequest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466acd7c",
   "metadata": {},
   "source": [
    "### 2. MEMBUAT DAN MELATIH MODEL AWAL (VERSI 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f95f7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup dan persiapan data selesai.\n",
      "Bentuk X_train: (55000, 28, 28, 1)\n",
      "Bentuk X_new untuk tes: (3, 28, 28, 1)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Memastikan output stabil di setiap eksekusi dengan mengatur random seed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Memuat dataset MNIST\n",
    "(X_train_full, y_train_full), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Normalisasi dan penambahan dimensi channel pada data gambar\n",
    "X_train_full = X_train_full[..., np.newaxis].astype(np.float32) / 255.\n",
    "X_test = X_test[..., np.newaxis].astype(np.float32) / 255.\n",
    "\n",
    "# Membagi data training menjadi set validasi dan training\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n",
    "# Mengambil 3 sampel pertama dari data test untuk prediksi\n",
    "X_new = X_test[:3]\n",
    "\n",
    "print(\"Setup dan persiapan data selesai.\")\n",
    "print(f\"Bentuk X_train: {X_train.shape}\")\n",
    "print(f\"Bentuk X_new untuk tes: {X_new.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f41e3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750438114.312566  269604 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "W0000 00:00:1750438114.857594  270148 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750438117.078515  270142 service.cc:148] XLA service 0x7fd9fc004b70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750438117.079041  270142 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 2060, Compute Capability 7.5\n",
      "2025-06-20 23:48:37.115385: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1750438117.185948  270142 cuda_dnn.cc:529] Loaded cuDNN version 91000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  22/1719\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.1722 - loss: 2.2798"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750438118.186260  270142 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 9ms/step - accuracy: 0.7299 - loss: 1.0653 - val_accuracy: 0.9030 - val_loss: 0.3678\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8976 - loss: 0.3670 - val_accuracy: 0.9194 - val_loss: 0.2950\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9147 - loss: 0.3047 - val_accuracy: 0.9296 - val_loss: 0.2599\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 7ms/step - accuracy: 0.9247 - loss: 0.2702 - val_accuracy: 0.9358 - val_loss: 0.2362\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.9310 - loss: 0.2456 - val_accuracy: 0.9400 - val_loss: 0.2182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fdab544b5f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Functional API — model stabil dan bisa disimpan di SavedModel\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = keras.layers.Flatten()(inputs)\n",
    "x = keras.layers.Dense(100, activation=\"relu\")(x)\n",
    "outputs = keras.layers.Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile & train\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ad7e43",
   "metadata": {},
   "source": [
    "### 3. MENYIMPAN MODEL DALAM FORMAT SAVEDMODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46be476",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mmy_mnist_model\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      4\u001b[39m os.makedirs(model_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaved_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel berhasil disimpan dalam format SavedModel di: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m-- Menampilkan signature dari SavedModel secara langsung tanpa CLI --\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1432\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, export_dir, signatures, options)\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[32m   1431\u001b[39m metrics.IncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1434\u001b[39m metrics.IncrementWrite(write_version=\u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1467\u001b[39m, in \u001b[36msave_and_return_nodes\u001b[39m\u001b[34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[39m\n\u001b[32m   1463\u001b[39m saved_model = saved_model_pb2.SavedModel()\n\u001b[32m   1464\u001b[39m meta_graph_def = saved_model.meta_graphs.add()\n\u001b[32m   1466\u001b[39m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1468\u001b[39m saved_model.saved_model_schema_version = (\n\u001b[32m   1469\u001b[39m     constants.SAVED_MODEL_SCHEMA_VERSION)\n\u001b[32m   1471\u001b[39m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1682\u001b[39m, in \u001b[36m_build_meta_graph\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1655\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[32m   1656\u001b[39m \n\u001b[32m   1657\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1678\u001b[39m \u001b[33;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[32m   1679\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1681\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save_context.save_context(options):\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1604\u001b[39m, in \u001b[36m_build_meta_graph_impl\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1601\u001b[39m augmented_graph_view.set_signature(signature_map, wrapped_functions)\n\u001b[32m   1603\u001b[39m \u001b[38;5;66;03m# Use _SaveableView to provide a frozen listing of properties and functions.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1604\u001b[39m saveable_view = \u001b[43m_SaveableView\u001b[49m\u001b[43m(\u001b[49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1605\u001b[39m object_saver = checkpoint.TrackableSaver(augmented_graph_view)\n\u001b[32m   1606\u001b[39m asset_info, exported_graph = _fill_meta_graph_def(\n\u001b[32m   1607\u001b[39m     meta_graph_def=meta_graph_def,\n\u001b[32m   1608\u001b[39m     saveable_view=saveable_view,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1614\u001b[39m     defaults=defaults,\n\u001b[32m   1615\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:285\u001b[39m, in \u001b[36m_SaveableView.__init__\u001b[39m\u001b[34m(self, augmented_graph_view, options)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28mself\u001b[39m.augmented_graph_view = augmented_graph_view\n\u001b[32m    281\u001b[39m \u001b[38;5;28mself\u001b[39m.options = options\n\u001b[32m    283\u001b[39m (\u001b[38;5;28mself\u001b[39m._trackable_objects, \u001b[38;5;28mself\u001b[39m.node_paths, \u001b[38;5;28mself\u001b[39m.node_ids,\n\u001b[32m    284\u001b[39m  \u001b[38;5;28mself\u001b[39m._slot_variables, \u001b[38;5;28mself\u001b[39m.object_names) = (\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m      \u001b[43mcheckpoint_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mobjects_ids_and_slot_variables_and_paths\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43maugmented_graph_view\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    288\u001b[39m untraced_functions = \u001b[38;5;28mself\u001b[39m.augmented_graph_view.untraced_functions\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m untraced_functions:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/util.py:160\u001b[39m, in \u001b[36mobjects_ids_and_slot_variables_and_paths\u001b[39m\u001b[34m(graph_view, skip_slot_variables)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mobjects_ids_and_slot_variables_and_paths\u001b[39m(graph_view,\n\u001b[32m    143\u001b[39m                                              skip_slot_variables=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    144\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Traverse the object graph and list all accessible objects.\u001b[39;00m\n\u001b[32m    145\u001b[39m \n\u001b[32m    146\u001b[39m \u001b[33;03m  Looks for `Trackable` objects which are dependencies of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    158\u001b[39m \u001b[33;03m                object -> node id, slot variables, object_names)\u001b[39;00m\n\u001b[32m    159\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m160\u001b[39m   trackable_objects, node_paths = \u001b[43mgraph_view\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbreadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m   object_names = object_identity.ObjectIdentityDictionary()\n\u001b[32m    162\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m obj, path \u001b[38;5;129;01min\u001b[39;00m node_paths.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:124\u001b[39m, in \u001b[36mObjectGraphView.breadth_first_traversal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbreadth_first_traversal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_breadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:156\u001b[39m, in \u001b[36m_AugmentedGraphView._breadth_first_traversal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    151\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns all trackable objects in the SavedObjectGraph.\"\"\"\u001b[39;00m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# This method is overriden to merge all equivalent constant tensors and\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# Assets in the object graph.\u001b[39;00m\n\u001b[32m    155\u001b[39m trackable_objects, _ = (\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_breadth_first_traversal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    158\u001b[39m asset_paths = object_identity.ObjectIdentityDictionary()\n\u001b[32m    159\u001b[39m constant_captures = object_identity.ObjectIdentityDictionary()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:128\u001b[39m, in \u001b[36mObjectGraphView._breadth_first_traversal\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_breadth_first_traversal\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    127\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Find shortest paths to all dependencies of self.root.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_descendants_with_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/trackable_view.py:111\u001b[39m, in \u001b[36mTrackableView._descendants_with_paths\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m current_trackable = to_visit.popleft()\n\u001b[32m    110\u001b[39m bfs_sorted.append(current_trackable)\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, dependency \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_trackable\u001b[49m\u001b[43m)\u001b[49m.items():\n\u001b[32m    112\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m dependency \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m node_paths:\n\u001b[32m    113\u001b[39m     node_paths[dependency] = (\n\u001b[32m    114\u001b[39m         node_paths[current_trackable] +\n\u001b[32m    115\u001b[39m         (base.TrackableReference(name, dependency),))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:97\u001b[39m, in \u001b[36mObjectGraphView.children\u001b[39m\u001b[34m(self, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     86\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns all child trackables attached to obj.\u001b[39;00m\n\u001b[32m     87\u001b[39m \n\u001b[32m     88\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     94\u001b[39m \u001b[33;03m  Dictionary of all children attached to the object with name to trackable.\u001b[39;00m\n\u001b[32m     95\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     96\u001b[39m children = {}\n\u001b[32m---> \u001b[39m\u001b[32m97\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.list_children(obj, **kwargs):\n\u001b[32m     98\u001b[39m   children[name] = ref\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:190\u001b[39m, in \u001b[36m_AugmentedGraphView.list_children\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._children_cache:\n\u001b[32m    188\u001b[39m   children = \u001b[38;5;28mself\u001b[39m._children_cache[obj] = {}\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSaveType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun.ConcreteFunction):\n\u001b[32m    195\u001b[39m       child = \u001b[38;5;28mself\u001b[39m._maybe_uncache_variable_captures(child)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[39m, in \u001b[36mObjectGraphView.list_children\u001b[39m\u001b[34m(self, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m children = []\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.items():\n\u001b[32m     77\u001b[39m   children.append(base.TrackableReference(name, ref))\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/trackable_view.py:85\u001b[39m, in \u001b[36mTrackableView.children\u001b[39m\u001b[34m(cls, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m children = {}\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj._trackable_children(save_type, **kwargs).items():\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m   ref = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_trackable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m   children[name] = ref\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/trackable/converter.py:31\u001b[39m, in \u001b[36mconvert_to_trackable\u001b[39m\u001b[34m(obj, parent)\u001b[39m\n\u001b[32m     29\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m     30\u001b[39m obj = data_structures.wrap_or_unwrap(obj)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtensor_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_tf_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     32\u001b[39m     obj.dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (dtypes.variant, dtypes.resource) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m resource_variable_ops.is_resource_variable(obj)):\n\u001b[32m     34\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_utils.TrackableConstant(obj, parent)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base.Trackable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/tensor_util.py:1163\u001b[39m, in \u001b[36mis_tf_type\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mis_tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[32m   1138\u001b[39m \n\u001b[32m   1139\u001b[39m \u001b[33;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m \u001b[33;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[32m   1162\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_type_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/typing.py:1871\u001b[39m, in \u001b[36m_ProtocolMeta.__instancecheck__\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n\u001b[32m   1869\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__protocol_attrs__:\n\u001b[32m   1870\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1871\u001b[39m         val = \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1872\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1873\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:1839\u001b[39m, in \u001b[36mgetattr_static\u001b[39m\u001b[34m(obj, attr, default)\u001b[39m\n\u001b[32m   1836\u001b[39m     dict_attr = _shadowed_dict(klass)\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types.MemberDescriptorType):\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m         instance_result = \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1841\u001b[39m     klass = obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:1793\u001b[39m, in \u001b[36m_check_instance\u001b[39m\u001b[34m(obj, attr)\u001b[39m\n\u001b[32m   1791\u001b[39m instance_dict = {}\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m     instance_dict = \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__dict__\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "# Buat folder model jika belum ada\n",
    "model_dir = \"my_mnist_model\"\n",
    "model_name = \"my_mnist_model\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "tf.saved_model.save(model, model_dir)\n",
    "print(f\"Model berhasil disimpan dalam format SavedModel di: {model_dir}\")\n",
    "\n",
    "print(\"\\n-- Menampilkan signature dari SavedModel secara langsung tanpa CLI --\")\n",
    "model = tf.saved_model.load(model_dir)\n",
    "signature = loaded_model.signatures[\"serving_default\"]\n",
    "print(\"Input Signature:\")\n",
    "print(signature.structured_input_signature)\n",
    "print(\"Output Signature:\")\n",
    "print(signature.structured_outputs)\n",
    "\n",
    "# Menampilkan struktur direktori dari SavedModel\n",
    "print(\"\\nStruktur direktori SavedModel yang dihasilkan:\")\n",
    "for root, dirs, files in os.walk(model_name):\n",
    "    indent = '    ' * root.count(os.sep)\n",
    "    print('{}{}/'.format(indent, os.path.basename(root)))\n",
    "    for filename in files:\n",
    "        print('{}{}'.format(indent + '    ', filename))\n",
    "\n",
    "# Menggunakan saved_model_cli untuk menginspeksi model\n",
    "print(\"\\nInspeksi model menggunakan saved_model_cli:\")\n",
    "try:\n",
    "    print(\"\\n-- Menampilkan semua tag set dan signature defs --\")\n",
    "    # Di lingkungan non-shell, lebih aman menggunakan list daripada string\n",
    "    print(\"\\n-- Menampilkan signature dari SavedModel secara langsung tanpa CLI --\")\n",
    "    loaded_model = tf.saved_model.load(model_dir)\n",
    "    signature = loaded_model.signatures[\"serving_default\"]\n",
    "    print(\"Input Signature:\")\n",
    "    print(signature.structured_input_signature)\n",
    "    print(\"Output Signature:\")\n",
    "    print(signature.structured_outputs)\n",
    "    \n",
    "    print(\"\\n-- Menampilkan detail signature 'serving_default' --\")\n",
    "    subprocess.run(\n",
    "        [\"saved_model_cli\", \"show\", \"--dir\", model_dir, \"--tag_set\", \"serve\", \"--signature_def\", \"serving_default\"],\n",
    "        check=True\n",
    "    )\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    print(\"Peringatan: `saved_model_cli` tidak ditemukan. Lewati inspeksi CLI.\")\n",
    "\n",
    "print(\"\\nPenyimpanan model selesai.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf5d5fc",
   "metadata": {},
   "source": [
    "### 4. MENJALANKAN TENSORFLOW SERVING & MENGIRIM REQUEST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08589223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencoba menjalankan TensorFlow Model Server di background...\n",
      "\n",
      "ERROR: Tidak dapat menjalankan atau terhubung ke TensorFlow Model Server.\n",
      "Pastikan `tensorflow_model_server` terinstal dan dapat diakses, atau jalankan via Docker.\n",
      "Detail error: [Errno 2] No such file or directory: 'tensorflow_model_server'\n",
      "\n",
      "Deploy dan query model versi 1 selesai.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TensorFlow Serving harus diinstal. Anda bisa menggunakan Docker (rekomendasi) atau\n",
    "# menginstalnya langsung:\n",
    "#\n",
    "# Opsi 1 (Docker):\n",
    "# docker run -it --rm -p 8500:8500 -p 8501:8501 \\\n",
    "#    -v \"$(pwd)/my_mnist_model:/models/my_mnist_model\" \\\n",
    "#    -e MODEL_NAME=my_mnist_model \\\n",
    "#    tensorflow/serving\n",
    "#\n",
    "# Opsi 2 (Instalasi Lokal):\n",
    "# apt-get install tensorflow-model-server\n",
    "#\n",
    "# Skrip ini akan mencoba menjalankan `tensorflow_model_server` di background.\n",
    "# Pastikan `tensorflow-model-server` terinstal dan bisa diakses dari terminal.\n",
    "\n",
    "model_dir = os.path.abspath(os.path.join(model_dir, \"..\"))\n",
    "server_proc = None\n",
    "model_name = os.path.basename(model_dir)\n",
    "try:\n",
    "    # Menjalankan TensorFlow Model Server sebagai proses background\n",
    "    print(\"Mencoba menjalankan TensorFlow Model Server di background...\")\n",
    "    command = [\n",
    "        \"tensorflow_model_server\",\n",
    "        \"--rest_api_port=8501\",\n",
    "        \"--port=8500\",\n",
    "        f\"--model_name={model_name}\",\n",
    "        f\"--model_base_path={model_dir}\"\n",
    "    ]\n",
    "    \n",
    "    # Menggunakan Popen untuk menjalankan server di background\n",
    "    server_proc = subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    print(f\"Server berjalan dengan PID: {server_proc.pid}\")\n",
    "    \n",
    "    # Beri waktu beberapa detik agar server siap\n",
    "    print(\"Menunggu server siap (10 detik)...\")\n",
    "    time.sleep(10)\n",
    "\n",
    "    # --- 4.1 Menggunakan REST API ---\n",
    "    print(\"\\n--- 4.1 Mengirim request via REST API ---\")\n",
    "    \n",
    "    # Menyiapkan data request dalam format JSON\n",
    "    input_data_json = json.dumps({\n",
    "        \"signature_name\": \"serving_default\",\n",
    "        \"instances\": X_new.tolist(),\n",
    "    })\n",
    "    \n",
    "    # URL untuk endpoint predict REST API\n",
    "    SERVER_URL = f'http://localhost:8501/v1/models/{model_name}:predict'\n",
    "    \n",
    "    # Mengirim request POST\n",
    "    response = requests.post(SERVER_URL, data=input_data_json)\n",
    "    response.raise_for_status() # Akan error jika status code bukan 2xx\n",
    "    \n",
    "    predictions = response.json()['predictions']\n",
    "    y_proba_rest = np.array(predictions)\n",
    "    \n",
    "    print(\"Hasil prediksi dari REST API:\")\n",
    "    print(y_proba_rest.round(2))\n",
    "\n",
    "    # --- 4.2 Menggunakan gRPC API ---\n",
    "    print(\"\\n--- 4.2 Mengirim request via gRPC API ---\")\n",
    "    \n",
    "    # Menyiapkan request gRPC\n",
    "    request_grpc = PredictRequest()\n",
    "    request_grpc.model_spec.name = model_name\n",
    "    request_grpc.model_spec.signature_name = \"serving_default\"\n",
    "    input_name = model.input_names[0]\n",
    "    request_grpc.inputs[input_name].CopyFrom(tf.make_tensor_proto(X_new))\n",
    "    \n",
    "    # Membuat channel dan stub gRPC\n",
    "    channel = grpc.insecure_channel('localhost:8500')\n",
    "    predict_service = prediction_service_pb2_grpc.PredictionServiceStub(channel)\n",
    "    \n",
    "    # Mengirim request gRPC\n",
    "    response_grpc = predict_service.Predict(request_grpc, timeout=10.0)\n",
    "    \n",
    "    # Mengonversi hasil gRPC (protobuf) kembali ke NumPy array\n",
    "    output_name = model.output_names[0]\n",
    "    outputs_proto = response_grpc.outputs[output_name]\n",
    "    y_proba_grpc = tf.make_ndarray(outputs_proto) # Cara mudah jika TF terinstall\n",
    "    \n",
    "    print(\"Hasil prediksi dari gRPC API:\")\n",
    "    print(y_proba_grpc.round(2))\n",
    "    \n",
    "except (FileNotFoundError, requests.exceptions.ConnectionError) as e:\n",
    "    print(f\"\\nERROR: Tidak dapat menjalankan atau terhubung ke TensorFlow Model Server.\")\n",
    "    print(\"Pastikan `tensorflow_model_server` terinstal dan dapat diakses, atau jalankan via Docker.\")\n",
    "    print(f\"Detail error: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nTerjadi error: {e}\")\n",
    "finally:\n",
    "    # Memastikan server dihentikan setelah selesai\n",
    "    if server_proc:\n",
    "        print(\"\\n\\nMenghentikan TensorFlow Model Server...\")\n",
    "        server_proc.terminate()\n",
    "        server_proc.wait()\n",
    "        print(\"Server dihentikan.\")\n",
    "\n",
    "print(\"\\nDeploy dan query model versi 1 selesai.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e76c5b6",
   "metadata": {},
   "source": [
    "### 5. DEPLOY VERSI MODEL BARU (VERSI 2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c58d8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardi/miniconda3/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model versi 2...\n",
      "Epoch 1/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 7ms/step - accuracy: 0.6493 - loss: 1.1883 - val_accuracy: 0.9060 - val_loss: 0.3444\n",
      "Epoch 2/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9011 - loss: 0.3455 - val_accuracy: 0.9238 - val_loss: 0.2790\n",
      "Epoch 3/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 8ms/step - accuracy: 0.9179 - loss: 0.2864 - val_accuracy: 0.9310 - val_loss: 0.2449\n",
      "Epoch 4/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9285 - loss: 0.2495 - val_accuracy: 0.9394 - val_loss: 0.2194\n",
      "Epoch 5/5\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9358 - loss: 0.2218 - val_accuracy: 0.9436 - val_loss: 0.2000\n",
      "\n",
      "Menyimpan model versi 2 ke path: Deep-Learning/0002\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "this __dict__ descriptor does not support '_DictWrapper' objects",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 38\u001b[39m\n\u001b[32m     36\u001b[39m model_path_v2 = os.path.join(model_name, model_version_v2) \u001b[38;5;66;03m# model_name dari sel sebelumnya\u001b[39;00m\n\u001b[32m     37\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMenyimpan model versi 2 ke path: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_path_v2\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m38\u001b[39m \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43msaved_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_v2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_path_v2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mMenunggu TensorFlow Serving (yang sedang berjalan) memuat model versi 2...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Beri waktu sekitar 10-15 detik agar TFS mendeteksi folder model baru\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1432\u001b[39m, in \u001b[36msave\u001b[39m\u001b[34m(obj, export_dir, signatures, options)\u001b[39m\n\u001b[32m   1430\u001b[39m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[32m   1431\u001b[39m metrics.IncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[32m-> \u001b[39m\u001b[32m1432\u001b[39m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1434\u001b[39m metrics.IncrementWrite(write_version=\u001b[33m\"\u001b[39m\u001b[33m2\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1467\u001b[39m, in \u001b[36msave_and_return_nodes\u001b[39m\u001b[34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[39m\n\u001b[32m   1463\u001b[39m saved_model = saved_model_pb2.SavedModel()\n\u001b[32m   1464\u001b[39m meta_graph_def = saved_model.meta_graphs.add()\n\u001b[32m   1466\u001b[39m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths = (\n\u001b[32m-> \u001b[39m\u001b[32m1467\u001b[39m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   1468\u001b[39m saved_model.saved_model_schema_version = (\n\u001b[32m   1469\u001b[39m     constants.SAVED_MODEL_SCHEMA_VERSION)\n\u001b[32m   1471\u001b[39m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[32m   1472\u001b[39m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1682\u001b[39m, in \u001b[36m_build_meta_graph\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1655\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[32m   1656\u001b[39m \n\u001b[32m   1657\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1678\u001b[39m \u001b[33;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[32m   1679\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1681\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m save_context.save_context(options):\n\u001b[32m-> \u001b[39m\u001b[32m1682\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:1592\u001b[39m, in \u001b[36m_build_meta_graph_impl\u001b[39m\u001b[34m(obj, signatures, options, meta_graph_def)\u001b[39m\n\u001b[32m   1590\u001b[39m augmented_graph_view = _AugmentedGraphView(obj)\n\u001b[32m   1591\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m signatures \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1592\u001b[39m   signatures = \u001b[43msignature_serialization\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfind_function_to_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1593\u001b[39m \u001b[43m      \u001b[49m\u001b[43maugmented_graph_view\u001b[49m\n\u001b[32m   1594\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1596\u001b[39m signatures, wrapped_functions, defaults = (\n\u001b[32m   1597\u001b[39m     signature_serialization.canonicalize_signatures(signatures)\n\u001b[32m   1598\u001b[39m )\n\u001b[32m   1599\u001b[39m signature_serialization.validate_augmented_graph_view(augmented_graph_view)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/signature_serialization.py:109\u001b[39m, in \u001b[36mfind_function_to_export\u001b[39m\u001b[34m(saveable_view)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;66;03m# TODO(b/205014194): Discuss removing this behaviour. It can lead to WTFs when\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# a user decides to annotate more functions with tf.function and suddenly\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# serving that model way later in the process stops working.\u001b[39;00m\n\u001b[32m    108\u001b[39m possible_signatures = []\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m children:\n\u001b[32m    110\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, (def_function.Function, defun.ConcreteFunction)):\n\u001b[32m    111\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/saved_model/save.py:190\u001b[39m, in \u001b[36m_AugmentedGraphView.list_children\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._children_cache:\n\u001b[32m    188\u001b[39m   children = \u001b[38;5;28mself\u001b[39m._children_cache[obj] = {}\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m   \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_AugmentedGraphView\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_children\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m      \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m      \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSaveType\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSAVEDMODEL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m      \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_serialization_cache\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    194\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(child, defun.ConcreteFunction):\n\u001b[32m    195\u001b[39m       child = \u001b[38;5;28mself\u001b[39m._maybe_uncache_variable_captures(child)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/graph_view.py:75\u001b[39m, in \u001b[36mObjectGraphView.list_children\u001b[39m\u001b[34m(self, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     64\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns list of all child trackables attached to obj.\u001b[39;00m\n\u001b[32m     65\u001b[39m \n\u001b[32m     66\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     72\u001b[39m \u001b[33;03m  List of all children attached to the object.\u001b[39;00m\n\u001b[32m     73\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     74\u001b[39m children = []\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mObjectGraphView\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m                       \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchildren\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.items():\n\u001b[32m     77\u001b[39m   children.append(base.TrackableReference(name, ref))\n\u001b[32m     79\u001b[39m \u001b[38;5;66;03m# GraphView objects may define children of the root object that are not\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[38;5;66;03m# actually attached, e.g. a Checkpoint object's save_counter.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/checkpoint/trackable_view.py:85\u001b[39m, in \u001b[36mTrackableView.children\u001b[39m\u001b[34m(cls, obj, save_type, **kwargs)\u001b[39m\n\u001b[32m     83\u001b[39m children = {}\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, ref \u001b[38;5;129;01min\u001b[39;00m obj._trackable_children(save_type, **kwargs).items():\n\u001b[32m---> \u001b[39m\u001b[32m85\u001b[39m   ref = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert_to_trackable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mref\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     86\u001b[39m   children[name] = ref\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m children\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/trackable/converter.py:31\u001b[39m, in \u001b[36mconvert_to_trackable\u001b[39m\u001b[34m(obj, parent)\u001b[39m\n\u001b[32m     29\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m obj\n\u001b[32m     30\u001b[39m obj = data_structures.wrap_or_unwrap(obj)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[43mtensor_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_tf_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     32\u001b[39m     obj.dtype \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (dtypes.variant, dtypes.resource) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m resource_variable_ops.is_resource_variable(obj)):\n\u001b[32m     34\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_utils.TrackableConstant(obj, parent)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, base.Trackable):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/framework/tensor_util.py:1163\u001b[39m, in \u001b[36mis_tf_type\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m   1135\u001b[39m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mis_tensor\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mis_tf_type\u001b[39m(x):  \u001b[38;5;66;03m# pylint: disable=invalid-name\u001b[39;00m\n\u001b[32m   1137\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Checks whether `x` is a TF-native type that can be passed to many TF ops.\u001b[39;00m\n\u001b[32m   1138\u001b[39m \n\u001b[32m   1139\u001b[39m \u001b[33;03m  Use `is_tensor` to differentiate types that can ingested by TensorFlow ops\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1161\u001b[39m \u001b[33;03m    `True` if `x` is a TensorFlow-native type.\u001b[39;00m\n\u001b[32m   1162\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1163\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtf_type_classes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/typing.py:1871\u001b[39m, in \u001b[36m_ProtocolMeta.__instancecheck__\u001b[39m\u001b[34m(cls, instance)\u001b[39m\n\u001b[32m   1869\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m.__protocol_attrs__:\n\u001b[32m   1870\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1871\u001b[39m         val = \u001b[43mgetattr_static\u001b[49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1872\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1873\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:1839\u001b[39m, in \u001b[36mgetattr_static\u001b[39m\u001b[34m(obj, attr, default)\u001b[39m\n\u001b[32m   1836\u001b[39m     dict_attr = _shadowed_dict(klass)\n\u001b[32m   1837\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (dict_attr \u001b[38;5;129;01mis\u001b[39;00m _sentinel \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1838\u001b[39m         \u001b[38;5;28mtype\u001b[39m(dict_attr) \u001b[38;5;129;01mis\u001b[39;00m types.MemberDescriptorType):\n\u001b[32m-> \u001b[39m\u001b[32m1839\u001b[39m         instance_result = \u001b[43m_check_instance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1840\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1841\u001b[39m     klass = obj\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/lib/python3.12/inspect.py:1793\u001b[39m, in \u001b[36m_check_instance\u001b[39m\u001b[34m(obj, attr)\u001b[39m\n\u001b[32m   1791\u001b[39m instance_dict = {}\n\u001b[32m   1792\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1793\u001b[39m     instance_dict = \u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getattribute__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m__dict__\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[32m   1795\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: this __dict__ descriptor does not support '_DictWrapper' objects"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Pastikan variabel dari sel sebelumnya tersedia (X_train, y_train, dll.)\n",
    "# dan server untuk v1 sedang berjalan.\n",
    "\n",
    "# 1. MEMBUAT DAN MELATIH MODEL VERSI 2\n",
    "# =====================================\n",
    "\n",
    "# Membuat model baru dengan arsitektur berbeda\n",
    "model_v2 = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28]), # Menggunakan input shape 28x28 untuk MNIST\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(50, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "# Mengompilasi model v2\n",
    "model_v2.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                 optimizer=keras.optimizers.SGD(learning_rate=1e-2),\n",
    "                 metrics=[\"accuracy\"])\n",
    "\n",
    "print(\"\\nMelatih model versi 2...\")\n",
    "# Asumsi X_train, y_train, X_valid, y_valid sudah ada dari sel sebelumnya\n",
    "history_v2 = model_v2.fit(X_train, y_train, epochs=5, validation_data=(X_valid, y_valid), verbose=1)\n",
    "\n",
    "\n",
    "# 2. MENYIMPAN DAN MENDEPLOY MODEL VERSI 2 SECARA OTOMATIS\n",
    "# ========================================================\n",
    "\n",
    "# Menentukan path untuk model versi 2\n",
    "model_version_v2 = \"0002\"\n",
    "model_path_v2 = os.path.join(model_name, model_version_v2) # model_name dari sel sebelumnya\n",
    "print(f\"\\nMenyimpan model versi 2 ke path: {model_path_v2}\")\n",
    "tf.saved_model.save(model_v2, model_path_v2)\n",
    "\n",
    "print(\"\\nMenunggu TensorFlow Serving (yang sedang berjalan) memuat model versi 2...\")\n",
    "# Beri waktu sekitar 10-15 detik agar TFS mendeteksi folder model baru\n",
    "time.sleep(15)\n",
    "\n",
    "# 3. MENGIRIM PERMINTAAN PREDIKSI KE SERVER\n",
    "# ============================================\n",
    "# Kita tidak perlu memulai server baru. Cukup kirim request ke URL server yang sama.\n",
    "# TFS akan secara otomatis menggunakan versi model terbaru (0002).\n",
    "\n",
    "try:\n",
    "    print(\"\\nMengirim request lagi ke server (seharusnya sudah menggunakan model v2)...\")\n",
    "    \n",
    "    # Asumsi SERVER_URL dan input_data_json sudah ada dari sel sebelumnya\n",
    "    response_v2 = requests.post(SERVER_URL, data=input_data_json)\n",
    "    response_v2.raise_for_status()\n",
    "    \n",
    "    predictions_v2 = response_v2.json()['predictions']\n",
    "    y_proba_v2 = np.array(predictions_v2)\n",
    "    \n",
    "    print(\"Hasil prediksi dari model versi 2:\")\n",
    "    print(y_proba_v2.round(2))\n",
    "    \n",
    "    # Membandingkan dengan prediksi dari model pertama (jika ada)\n",
    "    # print(\"\\nHasil prediksi dari model versi 1 (sebelumnya):\")\n",
    "    # print(y_proba_v1.round(2)) # y_proba_v1 dari sel sebelumnya\n",
    "\n",
    "except (NameError, requests.exceptions.RequestException) as e:\n",
    "    print(f\"\\nERROR: Gagal mengirim permintaan ke TensorFlow Model Server.\")\n",
    "    print(\"Pastikan variabel SERVER_URL dan input_data_json sudah ada, dan server sedang berjalan.\")\n",
    "    print(f\"Detail error: {e}\")\n",
    "\n",
    "print(\"\\nDemonstrasi deploy model versi baru selesai.\\n\")\n",
    "# Jangan terminate server di sini agar bisa digunakan di sel berikutnya jika perlu.\n",
    "# Proses server utama akan dihentikan di akhir notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1629a448",
   "metadata": {},
   "source": [
    "### 6. (OPSIONAL) DEPLOY KE GOOGLE CLOUD AI PLATFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9556430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagian ini dinonaktifkan karena memerlukan setup spesifik di Google Cloud.\n",
    "# Anda perlu memiliki project_id dan file kredensial JSON.\n",
    "# Jika Anda ingin menjalankannya, hapus komentar dan pastikan\n",
    "# pustaka `google-api-python-client` terinstal.\n",
    "\n",
    "# print(\"=== BAGIAN 6: DEPLOY KE GOOGLE CLOUD AI PLATFORM (Dinonaktifkan) ===\")\n",
    "# project_id = \"your-gcp-project-id\"\n",
    "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"my_service_account_private_key.json\"\n",
    "#\n",
    "# if os.path.exists(os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]):\n",
    "#     import googleapiclient.discovery\n",
    "#\n",
    "#     model_id = \"my_mnist_model\"\n",
    "#     model_path_gcp = \"projects/{}/models/{}\".format(project_id, model_id)\n",
    "#     ml_resource = googleapiclient.discovery.build(\"ml\", \"v1\").projects()\n",
    "#\n",
    "#     def predict_gcp(X):\n",
    "#         input_data_json = {\"signature_name\": \"serving_default\",\n",
    "#                            \"instances\": X.tolist()}\n",
    "#         request = ml_resource.predict(name=model_path_gcp, body=input_data_json)\n",
    "#         response = request.execute()\n",
    "#         if \"error\" in response:\n",
    "#             raise RuntimeError(response[\"error\"])\n",
    "#         output_name = model.output_names[0] # Mengambil nama output dari model\n",
    "#         return np.array([pred[output_name] for pred in response[\"predictions\"]])\n",
    "#\n",
    "#     try:\n",
    "#         print(\"Mengirim request ke Google Cloud AI Platform...\")\n",
    "#         Y_probas_gcp = predict_gcp(X_new)\n",
    "#         print(\"Hasil prediksi dari GCP:\")\n",
    "#         print(np.round(Y_probas_gcp, 2))\n",
    "#     except Exception as e:\n",
    "#         print(f\"Gagal melakukan prediksi di GCP: {e}\")\n",
    "# else:\n",
    "#     print(\"File kredensial GCP tidak ditemukan. Melewati bagian ini.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f014c9",
   "metadata": {},
   "source": [
    "### 7. PENGECEKAN GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ac13224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU terdeteksi: 1 buah\n",
      "  - PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Nama perangkat GPU utama: /device:GPU:0\n",
      "Apakah TensorFlow di-build dengan CUDA? Ya\n",
      "\n",
      "Daftar semua perangkat lokal yang terdeteksi:\n",
      "- Tipe: CPU, Nama: /device:CPU:0, Memori: 256 MB\n",
      "- Tipe: GPU, Nama: /device:GPU:0, Memori: 4057 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750438361.389138  269604 gpu_device.cc:2022] Created device /device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "I0000 00:00:1750438361.390961  269604 gpu_device.cc:2022] Created device /device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Kode ini telah diperbarui untuk menggunakan API modern TensorFlow 2.x\n",
    "# `tf.test.is_gpu_available()` sudah usang.\n",
    "\n",
    "# Cara modern untuk memeriksa ketersediaan GPU\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    print(f\"GPU terdeteksi: {len(gpus)} buah\")\n",
    "    for gpu in gpus:\n",
    "        print(f\"  - {gpu}\")\n",
    "    # Menampilkan nama perangkat GPU utama (jika ada)\n",
    "    # `tf.test.gpu_device_name()` masih berfungsi namun tidak direkomendasikan\n",
    "    try:\n",
    "        print(f\"Nama perangkat GPU utama: {tf.test.gpu_device_name()}\")\n",
    "    except:\n",
    "        print(\"Tidak bisa mendapatkan nama perangkat GPU utama via tf.test.gpu_device_name().\")\n",
    "\n",
    "else:\n",
    "    print(\"Tidak ada GPU yang terdeteksi.\")\n",
    "\n",
    "# Memeriksa apakah TensorFlow di-build dengan dukungan CUDA\n",
    "print(f\"Apakah TensorFlow di-build dengan CUDA? {'Ya' if tf.test.is_built_with_cuda() else 'Tidak'}\")\n",
    "\n",
    "# Menampilkan semua perangkat lokal yang terdeteksi oleh TensorFlow (CPU & GPU)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"\\nDaftar semua perangkat lokal yang terdeteksi:\")\n",
    "devices = device_lib.list_local_devices()\n",
    "for device in devices:\n",
    "    print(f\"- Tipe: {device.device_type}, Nama: {device.name}, Memori: {device.memory_limit // (1024*1024)} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e195da16",
   "metadata": {},
   "source": [
    "# Penjelasan\n",
    "---\n",
    "\n",
    "##  Catatan Eksekusi Lokal\n",
    "\n",
    "> **Error**: `TypeError: this __dict__ descriptor does not support '_DictWrapper' objects`  \n",
    "Error ini terjadi saat menggunakan `tf.saved_model.save()` dan umum ditemukan pada konfigurasi tertentu seperti Conda di WSL. Akibatnya, bagian demonstrasi TensorFlow Serving lokal tidak dapat dijalankan.\n",
    "\n",
    "---\n",
    "\n",
    "##  Ringkasan Eksperimen dan Hasil\n",
    "\n",
    "### 1. TensorFlow Serving (Local Deployment)\n",
    "\n",
    "- **Tujuan**: Men-serve model dengan latensi rendah dan throughput tinggi melalui REST atau gRPC.\n",
    "- **Workflow Ideal**:\n",
    "  - Melatih dan menyimpan model ke `SavedModel`.\n",
    "  - Menjalankan TFS via Docker, mengawasi direktori `my_mnist_model/{version}`.\n",
    "  - Mengirim request prediksi ke server.\n",
    "  - **Fitur Unggulan**: Auto model versioning — model baru pada direktori `0002` otomatis aktif.\n",
    "- **Hasil**: Tidak berjalan karena error `tf.saved_model.save()`.\n",
    "\n",
    ">  *Kesimpulan*: Meskipun gagal dieksekusi, TFS tetap merupakan opsi produksi terbaik untuk model serving skala besar.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Google AI Platform (Vertex AI)\n",
    "\n",
    "- **Tujuan**: Men-deploy model ke cloud managed platform milik Google.\n",
    "- **Langkah-langkah**:\n",
    "  - Upload model ke Google Cloud Storage (GCS).\n",
    "  - Buat objek model dan endpoint di Vertex AI.\n",
    "  - Deploy model ke endpoint dan uji dengan permintaan prediksi.\n",
    "- **Hasil**: Hanya dijelaskan secara konseptual, tidak dieksekusi.\n",
    "\n",
    ">  *Kesimpulan*: Vertex AI sangat cocok untuk perusahaan yang menginginkan skalabilitas, manajemen otomatis, dan integrasi penuh dalam ekosistem Google Cloud.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. TensorFlow Lite (Deployment ke Edge/Mobile)\n",
    "\n",
    "- **Tujuan**: Mengubah model Keras menjadi format ringan `.tflite` untuk perangkat dengan resource terbatas.\n",
    "- **Langkah Konversi**:\n",
    "  - `tf.lite.TFLiteConverter.from_keras_model(model)`\n",
    "  - Simpan ke file `.tflite`\n",
    "  - Jalankan inferensi menggunakan `tf.lite.Interpreter`\n",
    "- **Hasil**: Berhasil. Prediksi identik dengan model Keras asli → konversi sukses (lossless).\n",
    "\n",
    ">  *Kesimpulan*: TFLite adalah solusi solid untuk aplikasi ML di perangkat edge. Mudah dikonversi, cepat dieksekusi, dan hemat daya.\n",
    "\n",
    "---\n",
    "\n",
    "##  Perbandingan Metode Deployment\n",
    "\n",
    "| Metode             | Skenario Utama                | Kelebihan                                                    | Keterbatasan di Notebook                          |\n",
    "|--------------------|-------------------------------|---------------------------------------------------------------|---------------------------------------------------|\n",
    "| TensorFlow Serving | Server-side, skala besar       | Throughput tinggi, latensi rendah, auto-versioning            | Gagal disimpan karena environment TypeError       |\n",
    "| Vertex AI (GCP)    | Cloud-managed deployment       | Skalabilitas mudah, integrasi GCP, tanpa kelola server        | Instruksional, butuh akun GCP dan setup tambahan |\n",
    "| TensorFlow Lite    | Mobile & edge devices          | Ukuran kecil, cepat, bisa offline, hemat resource             | Berhasil dieksekusi dan tervalidasi               |\n",
    "\n",
    "---\n",
    "\n",
    "##  Kesimpulan Akhir\n",
    "\n",
    "Notebook ini menekankan pentingnya menyesuaikan metode deployment dengan konteks:\n",
    "\n",
    "- **TFS**: Untuk server dengan kendali penuh dan kebutuhan latensi rendah.\n",
    "- **Vertex AI**: Untuk deployment cloud skala besar tanpa repot manajemen server.\n",
    "- **TFLite**: Untuk aplikasi edge/mobile yang efisien dan ringan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
