{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b284eb9",
   "metadata": {},
   "source": [
    "### 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac56419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 11:29:11.227104: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750393751.266535  230925 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750393751.279173  230925 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-20 11:29:11.342242: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import sys\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "# Untuk progress bar, pastikan Anda sudah menginstal tqdm: pip install tqdm ipywidgets\n",
    "try:\n",
    "    from tqdm.notebook import trange\n",
    "except ImportError:\n",
    "    trange = lambda *args, **kwargs: args[0] # Fallback if tqdm is not installed\n",
    "\n",
    "# Memastikan versi Python\n",
    "assert sys.version_info >= (3, 5), \"Membutuhkan Python 3.5 atau lebih baru\"\n",
    "\n",
    "# Memastikan versi Scikit-Learn\n",
    "assert sklearn.__version__ >= \"0.20\", \"Membutuhkan Scikit-Learn 0.20 atau lebih baru\"\n",
    "\n",
    "# Memastikan versi TensorFlow\n",
    "# Perhatikan: %tensorflow_version hanya ada di Colab. Untuk lokal, abaikan ini.\n",
    "try:\n",
    "    # Mengatur versi TensorFlow untuk Colab jika dijalankan di sana\n",
    "    if 'google.colab' in sys.modules:\n",
    "        %tensorflow_version 2.x\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Pengaturan untuk output yang stabil dan plot\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Direktori untuk menyimpan gambar\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"deep\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    \"\"\"Fungsi untuk menyimpan gambar.\"\"\"\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Menyimpan gambar\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ee009e",
   "metadata": {},
   "source": [
    "### 2. Using TensorFlow like NumPy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102ba460",
   "metadata": {},
   "source": [
    "#### Tensors dan operasi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a1cf1",
   "metadata": {},
   "source": [
    "##### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae2c84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriks tensor:\n",
      " tf.Tensor(\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]], shape=(2, 3), dtype=float32)\n",
      "Bentuk matriks tensor: (2, 3)\n",
      "Tipe data matriks tensor: <dtype: 'float32'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750393758.142290  230925 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4057 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2060, pci bus id: 0000:01:00.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "# Membuat matriks tensor\n",
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(\"Matriks tensor:\\n\", t)\n",
    "print(\"Bentuk matriks tensor:\", t.shape)\n",
    "print(\"Tipe data matriks tensor:\", t.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50876b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skalar tensor: tf.Tensor(42, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Membuat skalar tensor\n",
    "scalar = tf.constant(42)\n",
    "print(\"\\nSkalar tensor:\", scalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5deca4",
   "metadata": {},
   "source": [
    "##### Ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77027f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t + 10:\n",
      " tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "tf.square(t):\n",
      " tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "t @ tf.transpose(t) (dot product):\n",
      " tf.Tensor(\n",
      "[[14. 32.]\n",
      " [32. 77.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1750393758.611591  230925 gpu_backend_lib.cc:579] Can't find libdevice directory ${CUDA_DIR}/nvvm/libdevice. This may result in compilation or runtime failures, if the program we try to run uses routines from libdevice.\n",
      "Searched for CUDA in the following directories:\n",
      "  ./cuda_sdk_lib\n",
      "  ipykernel_launcher.runfiles/cuda_nvcc\n",
      "  ipykern/cuda_nvcc\n",
      "  \n",
      "  /usr/local/cuda\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../../nvidia/cuda_nvcc\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../../../nvidia/cuda_nvcc\n",
      "  /home/ardi/miniconda3/lib/python3.12/site-packages/tensorflow/python/platform/../../cuda\n",
      "  .\n",
      "You can choose the search directory by setting xla_gpu_cuda_data_dir in HloModule's DebugOptions.  For most apps, setting the environment variable XLA_FLAGS=--xla_gpu_cuda_data_dir=/path/to/cuda will work.\n"
     ]
    }
   ],
   "source": [
    "print(\"t + 10:\\n\", t + 10)\n",
    "print(\"tf.square(t):\\n\", tf.square(t))\n",
    "print(\"t @ tf.transpose(t) (dot product):\\n\", t @ tf.transpose(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a87e5",
   "metadata": {},
   "source": [
    "##### Menggunakan `keras.backend`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a2b049",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K.square(K.transpose(t)) + 10:\n",
      " tf.Tensor(\n",
      "[[11. 26.]\n",
      " [14. 35.]\n",
      " [19. 46.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "K = keras.backend\n",
    "print(\"K.square(K.transpose(t)) + 10:\\n\", K.square(K.transpose(t)) + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb15244",
   "metadata": {},
   "source": [
    "##### Dari/Ke NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e394c0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy array ke Tensor:\n",
      " tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
      "Tensor ke NumPy array (t.numpy()):\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Tensor ke NumPy array (np.array(t)):\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "Operasi NumPy pada tensor (np.square(t)):\n",
      " [[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "print(\"NumPy array ke Tensor:\\n\", tf.constant(a))\n",
    "print(\"Tensor ke NumPy array (t.numpy()):\\n\", t.numpy())\n",
    "print(\"Tensor ke NumPy array (np.array(t)):\\n\", np.array(t))\n",
    "print(\"Operasi NumPy pada tensor (np.square(t)):\\n\", np.square(t)) # NumPy juga bisa operasi pada tensor TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa075b8",
   "metadata": {},
   "source": [
    "##### Tipe yang Konflik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5cd38af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (konflik tipe data float dan int):\n",
      " cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a int32 tensor [Op:AddV2] name: \n",
      "\n",
      "Error (konflik tipe data float32 dan float64):\n",
      " cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2] name: \n",
      "\n",
      "Hasil setelah casting tf.float64 ke tf.float32:\n",
      " tf.Tensor(42.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(\"\\nError (konflik tipe data float dan int):\\n\", ex)\n",
    "\n",
    "try:\n",
    "    tf.constant(2.0) + tf.constant(40., dtype=tf.float64)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(\"\\nError (konflik tipe data float32 dan float64):\\n\", ex)\n",
    "\n",
    "t2 = tf.constant(40., dtype=tf.float64)\n",
    "print(\"\\nHasil setelah casting tf.float64 ke tf.float32:\\n\", tf.constant(2.0) + tf.cast(t2, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef845396",
   "metadata": {},
   "source": [
    "##### Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b0a3676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor bytes:\n",
      " tf.Tensor(b'hello world', shape=(), dtype=string)\n",
      "Tensor string Unicode:\n",
      " tf.Tensor(b'caf\\xc3\\xa9', shape=(), dtype=string)\n",
      "\n",
      "Kode Unicode untuk 'café':\n",
      " tf.Tensor([ 99  97 102 233], shape=(4,), dtype=int32)\n",
      "Encoded UTF-8 bytes:\n",
      " tf.Tensor(b'caf\\xc3\\xa9', shape=(), dtype=string)\n",
      "Panjang string dalam karakter UTF-8:\n",
      " tf.Tensor(4, shape=(), dtype=int32)\n",
      "Decoded UTF-8 ke Unicode:\n",
      " tf.Tensor([ 99  97 102 233], shape=(4,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Tensor bytes:\\n\", tf.constant(b\"hello world\"))\n",
    "print(\"Tensor string Unicode:\\n\", tf.constant(\"café\"))\n",
    "\n",
    "u = tf.constant([ord(c) for c in \"café\"])\n",
    "print(\"\\nKode Unicode untuk 'café':\\n\", u)\n",
    "b = tf.strings.unicode_encode(u, \"UTF-8\")\n",
    "print(\"Encoded UTF-8 bytes:\\n\", b)\n",
    "print(\"Panjang string dalam karakter UTF-8:\\n\", tf.strings.length(b, unit=\"UTF8_CHAR\"))\n",
    "print(\"Decoded UTF-8 ke Unicode:\\n\", tf.strings.unicode_decode(b, \"UTF-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b869b49c",
   "metadata": {},
   "source": [
    "##### String arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9be4edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Array string:\n",
      " tf.Tensor([b'Caf\\xc3\\xa9' b'Coffee' b'caff\\xc3\\xa8' b'\\xe5\\x92\\x96\\xe5\\x95\\xa1'], shape=(4,), dtype=string)\n",
      "Panjang setiap string dalam karakter UTF-8:\n",
      " tf.Tensor([4 6 5 2], shape=(4,), dtype=int32)\n",
      "Decoded string array:\n",
      " <tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n",
      "Mencetak objek RaggedTensor r:\n",
      " <tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857]]>\n"
     ]
    }
   ],
   "source": [
    "p = tf.constant([\"Café\", \"Coffee\", \"caffè\", \"咖啡\"])\n",
    "print(\"Array string:\\n\", p)\n",
    "print(\"Panjang setiap string dalam karakter UTF-8:\\n\", tf.strings.length(p, unit=\"UTF8_CHAR\"))\n",
    "r = tf.strings.unicode_decode(p, \"UTF8\")\n",
    "print(\"Decoded string array:\\n\", r)\n",
    "print(\"Mencetak objek RaggedTensor r:\\n\", r) # Akan mencetak representasi RaggedTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8987e929",
   "metadata": {},
   "source": [
    "##### Ragged tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a910319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemen kedua dari r (indeks 1):\n",
      " tf.Tensor([ 67 111 102 102 101 101], shape=(6,), dtype=int32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemen dari r dengan indexing 1:3 (dari indeks 1 sampai 2):\n",
      " <tf.RaggedTensor [[67, 111, 102, 102, 101, 101], [99, 97, 102, 102, 232]]>\n",
      "Menggabungkan r dan r2 (axis=0):\n",
      " <tf.RaggedTensor [[67, 97, 102, 233], [67, 111, 102, 102, 101, 101],\n",
      " [99, 97, 102, 102, 232], [21654, 21857], [65, 66], [], [67]]>\n",
      "Contoh tf.concat([r_temp1, r_temp2], axis=1):\n",
      " <tf.RaggedTensor [[1, 2, 7, 8], [3, 9], [4, 5, 6, 10, 11]]>\n",
      "Mengkodekan r3 ke UTF-8:\n",
      " tf.Tensor([b'DEF' b'G' b'H' b'IJ'], shape=(4,), dtype=string)\n",
      "Mengubah r menjadi dense tensor:\n",
      " tf.Tensor(\n",
      "[[   67    97   102   233     0     0]\n",
      " [   67   111   102   102   101   101]\n",
      " [   99    97   102   102   232     0]\n",
      " [21654 21857     0     0     0     0]], shape=(4, 6), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Contoh Ragged Tensor, yang dapat memiliki baris dengan panjang yang berbeda.\n",
    "print(\"Elemen kedua dari r (indeks 1):\\n\", r[1])\n",
    "print(\"Elemen dari r dengan indexing 1:3 (dari indeks 1 sampai 2):\\n\", r[1:3])\n",
    "\n",
    "r2 = tf.ragged.constant([[65, 66], [], [67]])\n",
    "print(\"Menggabungkan r dan r2 (axis=0):\\n\", tf.concat([r, r2], axis=0))\n",
    "\n",
    "# Contoh yang akan berfungsi:\n",
    "r_temp1 = tf.ragged.constant([[1, 2], [3], [4, 5, 6]])\n",
    "r_temp2 = tf.ragged.constant([[7, 8], [9], [10, 11]])\n",
    "print(\"Contoh tf.concat([r_temp1, r_temp2], axis=1):\\n\", tf.concat([r_temp1, r_temp2], axis=1))\n",
    "\n",
    "r3 = tf.ragged.constant([[68, 69, 70], [71], [72], [73, 74]]) # Ubah r3 agar bisa diencode\n",
    "print(\"Mengkodekan r3 ke UTF-8:\\n\", tf.strings.unicode_encode(r3, \"UTF-8\"))\n",
    "\n",
    "# Mengubah ragged tensor menjadi dense tensor (mengisi dengan nilai default, biasanya 0)\n",
    "# Perhatikan bahwa ini akan menambahkan padding jika baris memiliki panjang berbeda.\n",
    "print(\"Mengubah r menjadi dense tensor:\\n\", r.to_tensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b94cfc",
   "metadata": {},
   "source": [
    "##### Sparse tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cae88655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Tensor s:\n",
      " SparseTensor(indices=tf.Tensor(\n",
      "[[0 1]\n",
      " [1 0]\n",
      " [2 3]], shape=(3, 2), dtype=int64), values=tf.Tensor([1. 2. 3.], shape=(3,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n",
      "Mengubah sparse tensor ke dense tensor:\n",
      " tf.Tensor(\n",
      "[[0. 1. 0. 0.]\n",
      " [2. 0. 0. 0.]\n",
      " [0. 0. 0. 3.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s = tf.SparseTensor(indices=[[0, 1], [1, 0], [2, 3]],\n",
    "                    values=[1., 2., 3.],\n",
    "                    dense_shape=[3, 4])\n",
    "print(\"Sparse Tensor s:\\n\", s)\n",
    "print(\"Mengubah sparse tensor ke dense tensor:\\n\", tf.sparse.to_dense(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0a377a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil s * 2.0:\n",
      " tf.Tensor(\n",
      "[[0. 2. 0. 0.]\n",
      " [4. 0. 0. 0.]\n",
      " [0. 0. 0. 6.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s2 = s * 2.0\n",
    "print(\"Hasil s * 2.0:\\n\", tf.sparse.to_dense(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ea983c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (operasi aritmatika langsung pada SparseTensor):\n",
      " unsupported operand type(s) for +: 'SparseTensor' and 'float'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    s3 = s + 1. # Operasi ini tidak didukung langsung untuk SparseTensor\n",
    "except TypeError as ex:\n",
    "    print(\"\\nError (operasi aritmatika langsung pada SparseTensor):\\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82d5bfe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil tf.sparse.sparse_dense_matmul(s, s4):\n",
      " tf.Tensor(\n",
      "[[ 30.  40.]\n",
      " [ 20.  40.]\n",
      " [210. 240.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s4 = tf.constant([[10., 20.], [30., 40.], [50., 60.], [70., 80.]])\n",
    "print(\"Hasil tf.sparse.sparse_dense_matmul(s, s4):\\n\", tf.sparse.sparse_dense_matmul(s, s4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af9ea104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparse Tensor s5 (indeks tidak berurutan):\n",
      " SparseTensor(indices=tf.Tensor(\n",
      "[[0 2]\n",
      " [0 1]], shape=(2, 2), dtype=int64), values=tf.Tensor([1. 2.], shape=(2,), dtype=float32), dense_shape=tf.Tensor([3 4], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "s5 = tf.SparseTensor(indices=[[0, 2], [0, 1]], # Indeks tidak berurutan\n",
    "                     values=[1., 2.],\n",
    "                     dense_shape=[3, 4])\n",
    "print(\"\\nSparse Tensor s5 (indeks tidak berurutan):\\n\", s5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca6d0058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (indeks Sparse Tensor tidak terurut):\n",
      " {{function_node __wrapped__SparseToDense_device_/job:localhost/replica:0/task:0/device:GPU:0}} indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n",
      "\t [[{{node SparseToDense}}]] [Op:SparseToDense] name: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 11:29:19.148133: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: INVALID_ARGUMENT: indices[1] is out of order. Many sparse ops require sorted indices.\n",
      "  Use `tf.sparse.reorder` to create a correctly ordered copy.\n",
      "\n",
      "\n",
      "\t [[{{node SparseToDense}}]]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # tf.sparse.to_dense akan error jika indeks tidak terurut\n",
    "    tf.sparse.to_dense(s5)\n",
    "except tf.errors.InvalidArgumentError as ex:\n",
    "    print(\"\\nError (indeks Sparse Tensor tidak terurut):\\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b000aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparse Tensor s6 (setelah diurutkan):\n",
      " tf.Tensor(\n",
      "[[0. 2. 1. 0.]\n",
      " [0. 0. 0. 0.]\n",
      " [0. 0. 0. 0.]], shape=(3, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "s6 = tf.sparse.reorder(s5)\n",
    "print(\"Sparse Tensor s6 (setelah diurutkan):\\n\", tf.sparse.to_dense(s6))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19891253",
   "metadata": {},
   "source": [
    "##### Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "736dfbe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Union dari set1 dan set2:\n",
      " tf.Tensor(\n",
      "[[ 2  3  4  5  6  7]\n",
      " [ 0  7  9 10  0  0]], shape=(2, 6), dtype=int32)\n",
      "Difference dari set1 dan set2:\n",
      " tf.Tensor(\n",
      "[[2 3 7]\n",
      " [7 0 0]], shape=(2, 3), dtype=int32)\n",
      "Intersection dari set1 dan set2:\n",
      " tf.Tensor(\n",
      "[[5 0]\n",
      " [0 9]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "set1 = tf.constant([[2, 3, 5, 7], [7, 9, 0, 0]])\n",
    "set2 = tf.constant([[4, 5, 6], [9, 10, 0]])\n",
    "print(\"Union dari set1 dan set2:\\n\", tf.sparse.to_dense(tf.sets.union(set1, set2)))\n",
    "print(\"Difference dari set1 dan set2:\\n\", tf.sparse.to_dense(tf.sets.difference(set1, set2)))\n",
    "print(\"Intersection dari set1 dan set2:\\n\", tf.sparse.to_dense(tf.sets.intersection(set1, set2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfc5660",
   "metadata": {},
   "source": [
    "##### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97c6df77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variabel v awal:\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[1., 2., 3.],\n",
      "       [4., 5., 6.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "print(\"Variabel v awal:\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "038f7d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v setelah v.assign(2 * v):\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2.,  4.,  6.],\n",
      "       [ 8., 10., 12.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v.assign(2 * v)\n",
    "print(\"\\nv setelah v.assign(2 * v):\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "abb23180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v setelah v[0, 1].assign(42):\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2., 42.,  6.],\n",
      "       [ 8., 10., 12.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v[0, 1].assign(42)\n",
    "print(\"\\nv setelah v[0, 1].assign(42):\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c57272cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v setelah v[:, 2].assign([0., 1.]):\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2., 42.,  0.],\n",
      "       [ 8., 10.,  1.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v[:, 2].assign([0., 1.])\n",
    "print(\"\\nv setelah v[:, 2].assign([0., 1.]):\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d61d263c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error (tidak bisa menggunakan operator slicing Python biasa untuk assign):\n",
      " 'ResourceVariable' object does not support item assignment\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    v[1] = [7., 8., 9.] # Tidak bisa menggunakan operator slicing Python biasa\n",
    "except TypeError as ex:\n",
    "    print(\"\\nError (tidak bisa menggunakan operator slicing Python biasa untuk assign):\\n\", ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ecb08a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v setelah scatter_nd_update:\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[100.,  42.,   0.],\n",
      "       [  8.,  10., 200.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]],\n",
    "                    updates=[100., 200.])\n",
    "print(\"\\nv setelah scatter_nd_update:\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d013e38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "v setelah scatter_update:\n",
      " <tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[4., 5., 6.],\n",
      "       [1., 2., 3.]], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "sparse_delta = tf.IndexedSlices(values=[[1., 2., 3.], [4., 5., 6.]],\n",
    "                                indices=[1, 0])\n",
    "v.scatter_update(sparse_delta)\n",
    "print(\"\\nv setelah scatter_update:\\n\", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83961136",
   "metadata": {},
   "source": [
    "##### Tensor Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8403ab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membaca elemen kedua dari TensorArray (indeks 1):\n",
      " tf.Tensor([ 3. 10.], shape=(2,), dtype=float32)\n",
      "Menumpuk TensorArray menjadi satu tensor:\n",
      " tf.Tensor(\n",
      "[[1. 2.]\n",
      " [0. 0.]\n",
      " [5. 7.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "array = tf.TensorArray(dtype=tf.float32, size=3)\n",
    "array = array.write(0, tf.constant([1., 2.]))\n",
    "array = array.write(1, tf.constant([3., 10.]))\n",
    "array = array.write(2, tf.constant([5., 7.]))\n",
    "\n",
    "print(\"Membaca elemen kedua dari TensorArray (indeks 1):\\n\", array.read(1))\n",
    "print(\"Menumpuk TensorArray menjadi satu tensor:\\n\", array.stack())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9947dcd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean dari TensorArray:\n",
      " tf.Tensor([2. 3.], shape=(2,), dtype=float32)\n",
      "Variance dari TensorArray:\n",
      " tf.Tensor([4.6666665 8.666667 ], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "mean, variance = tf.nn.moments(array.stack(), axes=0)\n",
    "print(\"Mean dari TensorArray:\\n\", mean)\n",
    "print(\"Variance dari TensorArray:\\n\", variance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ac674",
   "metadata": {},
   "source": [
    "### 3. Customizing Models and Training Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e976fee",
   "metadata": {},
   "source": [
    "#### Custom loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4846c4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Memastikan eager execution diaktifkan (seharusnya sudah default di TF2.x, tapi untuk jaga-jaga)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "tf.data.experimental.enable_debug_mode()\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0e1c62a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    \"\"\"Fungsi Huber loss.\"\"\"\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) / 2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2a54e6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menyimpan gambar huber_loss_plot\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x350 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisasi Huber Loss\n",
    "plt.figure(figsize=(8, 3.5))\n",
    "z = np.linspace(-4, 4, 200)\n",
    "plt.plot(z, huber_fn(0, z), \"b-\", linewidth=2, label=\"huber($z$)\")\n",
    "plt.plot(z, z**2 / 2, \"b:\", linewidth=1, label=r\"$\\frac{1}{2}z^2$\")\n",
    "plt.plot([-1, -1], [0, huber_fn(0., -1.)], \"r--\")\n",
    "plt.plot([1, 1], [0, huber_fn(0., 1.)], \"r--\")\n",
    "plt.gca().axhline(y=0, color='k')\n",
    "plt.gca().axvline(x=0, color='k')\n",
    "plt.axis([-4, 4, 0, 4])\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"$z$\")\n",
    "plt.legend(fontsize=14)\n",
    "plt.title(\"Huber loss\", fontsize=14)\n",
    "save_fig(\"huber_loss_plot\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fabcb0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardi/miniconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Membangun model dengan custom loss function\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6efbe521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "Training set shape: (11610, 8)\n",
      "Validation set shape: (3870, 8)\n",
      "Test set shape: (5160, 8)\n",
      "\n",
      "Melatih model dengan custom Huber loss function:\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 107ms/step - loss: 1.0094 - mae: 1.4117 - val_loss: 0.2421 - val_mae: 0.5362\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 124ms/step - loss: 0.2050 - mae: 0.4992 - val_loss: 0.1882 - val_mae: 0.4742\n"
     ]
    }
   ],
   "source": [
    "# Menambahkan run_eagerly=True pada saat compile untuk memastikan eager execution\n",
    "# Ini seringkali membantu dengan custom loss/metric functions yang melakukan operasi numpy() secara implisit\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"], run_eagerly=True)\n",
    "\n",
    "\n",
    "print(\"Dataset info:\")\n",
    "print(f\"Training set shape: {X_train_scaled.shape}\")\n",
    "print(f\"Validation set shape: {X_valid_scaled.shape}\")\n",
    "print(f\"Test set shape: {X_test_scaled.shape}\")\n",
    "\n",
    "print(\"\\nMelatih model dengan custom Huber loss function:\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2,\n",
    "                   validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca63394",
   "metadata": {},
   "source": [
    "#### Saving/Loading Models with Custom Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e4edd00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model berhasil disimpan sebagai 'my_model_with_a_custom_loss.h5'\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan model\n",
    "model.save(\"my_model_with_a_custom_loss.h5\")\n",
    "print(\"\\nModel berhasil disimpan sebagai 'my_model_with_a_custom_loss.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7c9f7f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memuat model dengan custom_objects:\n",
      "\n",
      "Melanjutkan pelatihan model yang dimuat:\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 103ms/step - loss: 0.1964 - mae: 0.4868 - val_loss: 0.1772 - val_mae: 0.4538\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 105ms/step - loss: 0.1902 - mae: 0.4759 - val_loss: 0.1856 - val_mae: 0.4598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a58392390>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "# Memuat model (membutuhkan custom_objects)\n",
    "print(\"\\nMemuat model dengan custom_objects:\")\n",
    "model = keras.models.load_model(\"my_model_with_a_custom_loss.h5\",\n",
    "                                custom_objects={\"huber_fn\": huber_fn})\n",
    "\n",
    "# Setelah memuat model, kompilasi ulang dengan run_eagerly=True\n",
    "# Ini penting karena model yang dimuat mungkin kehilangan pengaturan eager execution\n",
    "model.compile(loss=huber_fn, optimizer=\"nadam\", metrics=[\"mae\"], run_eagerly=True)\n",
    "\n",
    "\n",
    "print(\"\\nMelanjutkan pelatihan model yang dimuat:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "395dfbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluasi model pada test set:\n",
      "Test Loss (Huber): 0.1880\n",
      "Test MAE: 0.4715\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "print(\"\\nEvaluasi model pada test set:\")\n",
    "test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Loss (Huber): {test_loss:.4f}\")\n",
    "print(f\"Test MAE: {test_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70a61bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Huber loss dengan threshold yang dapat dikonfigurasi\n",
    "def create_huber(threshold=1.0):\n",
    "    def huber_fn(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = threshold * tf.abs(error) - threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "    return huber_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43fa7c49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan Huber loss dengan threshold 2.0:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 113ms/step - loss: 0.2109 - mae: 0.4738 - val_loss: 0.2116 - val_mae: 0.4530\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 114ms/step - loss: 0.2037 - mae: 0.4636 - val_loss: 0.1961 - val_mae: 0.4500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a5848eea0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "print(\"\\nMelatih model dengan Huber loss dengan threshold 2.0:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8a963483",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_threshold_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ec7f7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melanjutkan pelatihan model yang dimuat dengan threshold 2.0:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 110ms/step - loss: 0.2087 - mae: 0.4689 - val_loss: 0.2223 - val_mae: 0.4566\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 127ms/step - loss: 0.1963 - mae: 0.4571 - val_loss: 0.1982 - val_mae: 0.4427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a582178f0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_threshold_2.h5\",\n",
    "                                custom_objects={\"huber_fn\": create_huber(2.0)})\n",
    "\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "print(\"\\nMelanjutkan pelatihan model yang dimuat dengan threshold 2.0:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d81df19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.saving import register_keras_serializable\n",
    "\n",
    "# Membuat class HuberLoss sebagai subclass keras.losses.Loss\n",
    "@register_keras_serializable()\n",
    "class HuberLoss(keras.losses.Loss):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        self.threshold = threshold\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) < self.threshold\n",
    "        squared_loss = tf.square(error) / 2\n",
    "        linear_loss  = self.threshold * tf.abs(error) - self.threshold**2 / 2\n",
    "        return tf.where(is_small_error, squared_loss, linear_loss)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9f94052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "af3eda91",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ade9a1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan HuberLoss class:\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 116ms/step - loss: 1.6055 - mae: 1.4915 - val_loss: 0.3467 - val_mae: 0.5657\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 136ms/step - loss: 0.2484 - mae: 0.5129 - val_loss: 0.2704 - val_mae: 0.5183\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a584a22d0>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "print(\"\\nMelatih model dengan HuberLoss class:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4863b99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_loss_class.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c28e204",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melanjutkan pelatihan model yang dimuat dengan HuberLoss class:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 108ms/step - loss: 0.2380 - mae: 0.5066 - val_loss: 0.2222 - val_mae: 0.4810\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 108ms/step - loss: 0.2266 - mae: 0.4962 - val_loss: 0.2398 - val_mae: 0.4858\n",
      "Threshold HuberLoss yang dimuat: 2.0\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_loss_class.h5\",\n",
    "                                custom_objects={\"HuberLoss\": HuberLoss})\n",
    "print(\"\\nMelanjutkan pelatihan model yang dimuat dengan HuberLoss class:\")\n",
    "\n",
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"])\n",
    "\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "print(\"Threshold HuberLoss yang dimuat:\", model.loss.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf485649",
   "metadata": {},
   "source": [
    "#### Custom Activation Functions, Initializers, Regularizers, and Constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8b8391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d8e9f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.initializers import Initializer\n",
    "from tensorflow.keras.regularizers import Regularizer\n",
    "from tensorflow.keras.constraints import Constraint\n",
    "\n",
    "# Custom activation function\n",
    "@register_keras_serializable()\n",
    "def my_softplus(z):\n",
    "    \"\"\"Fungsi aktivasi softplus kustom.\"\"\"\n",
    "    return tf.math.log(tf.exp(z) + 1.0)\n",
    "\n",
    "# Custom initializer\n",
    "@register_keras_serializable()\n",
    "class MyGlorotInitializer(Initializer):\n",
    "    def __call__(self, shape, dtype=None):\n",
    "        if dtype is None:\n",
    "            dtype = tf.float32  # Default dtype\n",
    "        stddev = tf.sqrt(2. / (shape[0] + shape[1]))\n",
    "        return tf.random.normal(shape, stddev=stddev, dtype=dtype)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "# Custom regularizer\n",
    "@register_keras_serializable()\n",
    "class MyL1Regularizer(Regularizer):\n",
    "    def __init__(self, factor=0.01):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, weights):\n",
    "        return self.factor * tf.reduce_sum(tf.abs(weights))\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}\n",
    "\n",
    "# Custom constraint\n",
    "@register_keras_serializable()\n",
    "class MyPositiveWeights(Constraint):\n",
    "    def __call__(self, weights):\n",
    "        return tf.where(weights < 0., tf.zeros_like(weights), weights)\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "# Membuat instance dari custom komponen\n",
    "my_glorot_initializer_instance = MyGlorotInitializer()\n",
    "my_l1_regularizer_instance = MyL1Regularizer(0.01)\n",
    "my_positive_weights_instance = MyPositiveWeights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "91b6be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perbaikan: Gunakan instance dari class custom untuk initializer, regularizer, dan constraint\n",
    "layer = keras.layers.Dense(1, activation=my_softplus,\n",
    "                            kernel_initializer=my_glorot_initializer_instance,\n",
    "                            kernel_regularizer=my_l1_regularizer_instance,\n",
    "                            kernel_constraint=my_positive_weights_instance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6355a5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bfd07d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer_instance,\n",
    "                       kernel_constraint=my_positive_weights_instance,\n",
    "                       kernel_initializer=my_glorot_initializer_instance),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b50ab1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan custom activation, initializer, regularizer, dan constraint:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 108ms/step - loss: 1.0727 - mae: 1.1630 - val_loss: 0.3746 - val_mae: 0.5655\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 109ms/step - loss: 0.3044 - mae: 0.5286 - val_loss: 0.3124 - val_mae: 0.5067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a6008e4e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setelah membangun model, compile dan latih\n",
    "model.compile(loss=HuberLoss(2.), optimizer=\"nadam\", metrics=[\"mae\"], run_eagerly=True) # Tambahkan run_eagerly=True\n",
    "print(\"\\nMelatih model dengan custom activation, initializer, regularizer, dan constraint:\")\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2,\n",
    "          validation_data=(X_valid_scaled.astype(np.float32), y_valid.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3f91a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b3b14251",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "        \"my_l1_regularizer\": my_l1_regularizer_instance,\n",
    "        \"my_positive_weights\": my_positive_weights_instance,\n",
    "        \"my_glorot_initializer\": my_glorot_initializer_instance,\n",
    "        \"my_softplus\": my_softplus,\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bff71039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat class MyL1Regularizer sebagai subclass keras.regularizers.Regularizer\n",
    "@register_keras_serializable()\n",
    "class MyL1Regularizer(keras.regularizers.Regularizer):\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    def __call__(self, weights):\n",
    "        return tf.reduce_sum(tf.abs(self.factor * weights))\n",
    "    def get_config(self):\n",
    "        return {\"factor\": self.factor}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2d6e1170",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "39cb349c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1, activation=my_softplus,\n",
    "                       kernel_regularizer=my_l1_regularizer_instance,\n",
    "                       kernel_constraint=my_positive_weights_instance,\n",
    "                       kernel_initializer=my_glorot_initializer_instance),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b27f8e21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan MyL1Regularizer class:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 110ms/step - loss: 2.4469 - mean_absolute_error: 1.1762 - val_loss: 3.0741 - val_mean_absolute_error: 0.6076\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 117ms/step - loss: 0.6622 - mean_absolute_error: 0.5600 - val_loss: 2.3182 - val_mean_absolute_error: 0.5429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a60138c80>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.MeanSquaredError(),\n",
    "              optimizer=\"nadam\",\n",
    "              metrics=[keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "print(\"\\nMelatih model dengan MyL1Regularizer class:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "60b6cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_many_custom_parts.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c09b7c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_many_custom_parts.h5\",\n",
    "    custom_objects={\n",
    "        \"my_l1_regularizer\": my_l1_regularizer_instance,\n",
    "        \"my_positive_weights\": my_positive_weights_instance,\n",
    "        \"my_glorot_initializer\": my_glorot_initializer_instance,\n",
    "        \"my_softplus\": my_softplus,\n",
    "        \"MeanSquaredError\": keras.losses.MeanSquaredError,\n",
    "        \"MeanAbsoluteError\": keras.metrics.MeanAbsoluteError\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c601108c",
   "metadata": {},
   "source": [
    "#### Custom Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a3a4a6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f103f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "62581622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan custom metric (huber_fn):\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 94ms/step - huber_fn: 1.4861 - loss: 3.3278\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 97ms/step - huber_fn: 0.2502 - loss: 0.5120\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a306fc5c0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Menggunakan fungsi huber_fn sebagai metrik\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
    "print(\"\\nMelatih model dengan custom metric (huber_fn):\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "718980ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 104ms/step - huber_fn: 0.2279 - loss: 0.1117\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 101ms/step - huber_fn: 0.2178 - loss: 0.1070\n"
     ]
    }
   ],
   "source": [
    "# Perbandingan loss dan metrik saat menggunakan sample_weight\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[create_huber(2.0)])\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7ed780c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss epoch 0: 0.1135\n",
      "Huber_fn (metric) epoch 0 * mean_sample_weight: 0.1137\n"
     ]
    }
   ],
   "source": [
    "# Periksa perbedaan antara loss dan metrik (akan ada perbedaan karena definisi)\n",
    "print(f\"\\nLoss epoch 0: {history.history['loss'][0]:.4f}\")\n",
    "print(f\"Huber_fn (metric) epoch 0 * mean_sample_weight: {history.history['huber_fn'][0] * sample_weight.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f72a66b",
   "metadata": {},
   "source": [
    "#### Streaming metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a5bb099d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Precision (update 1):\n",
      " tf.Tensor(0.8, shape=(), dtype=float32)\n",
      "Precision (update 2):\n",
      " tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "Hasil akhir Precision:\n",
      " tf.Tensor(0.5, shape=(), dtype=float32)\n",
      "Variabel Precision:\n",
      " [<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[4.]>, <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[4.]>]\n",
      "Variabel Precision setelah reset:\n",
      " [<Variable path=precision/true_positives, shape=(1,), dtype=float32, value=[0.]>, <Variable path=precision/false_positives, shape=(1,), dtype=float32, value=[0.]>]\n"
     ]
    }
   ],
   "source": [
    "# Contoh metrik streaming (misalnya, precision) dan cara membuat metrik streaming kustom.\n",
    "precision = keras.metrics.Precision()\n",
    "print(\"\\nPrecision (update 1):\\n\", precision([0, 1, 1, 1, 0, 1, 0, 1], [1, 1, 0, 1, 0, 1, 0, 1]))\n",
    "print(\"Precision (update 2):\\n\", precision([0, 1, 0, 0, 1, 0, 1, 1], [1, 0, 1, 1, 0, 0, 0, 0]))\n",
    "print(\"Hasil akhir Precision:\\n\", precision.result())\n",
    "print(\"Variabel Precision:\\n\", precision.variables)\n",
    "precision.reset_state()\n",
    "print(\"Variabel Precision setelah reset:\\n\", precision.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1ca16b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat class HuberMetric sebagai subclass keras.metrics.Metric\n",
    "@register_keras_serializable()\n",
    "class HuberMetric(keras.metrics.Metric):\n",
    "    def __init__(self, threshold=1.0, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.threshold = threshold\n",
    "        self.total = self.add_weight(name=\"total\", initializer=\"zeros\")\n",
    "        self.count = self.add_weight(name=\"count\", initializer=\"zeros\")\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        error = y_true - y_pred\n",
    "        is_small = tf.abs(error) < self.threshold\n",
    "        squared = 0.5 * tf.square(error)\n",
    "        linear = self.threshold * tf.abs(error) - 0.5 * self.threshold**2\n",
    "        metric = tf.where(is_small, squared, linear)\n",
    "        self.total.assign_add(tf.reduce_sum(metric))\n",
    "        self.count.assign_add(tf.cast(tf.size(y_true), tf.float32))\n",
    "    def result(self):\n",
    "        return self.total / self.count\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0aa97e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "HuberMetric (update 1):\n",
      " tf.Tensor(14.0, shape=(), dtype=float32)\n",
      "HuberMetric (update 2):\n",
      " tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "Hasil HuberMetric:\n",
      " tf.Tensor(7.0, shape=(), dtype=float32)\n",
      "Variabel HuberMetric:\n",
      " [<Variable path=huber_metric_1/total, shape=(), dtype=float32, value=21.0>, <Variable path=huber_metric_1/count, shape=(), dtype=float32, value=3.0>]\n",
      "Variabel HuberMetric setelah reset:\n",
      " [<Variable path=huber_metric_1/total, shape=(), dtype=float32, value=0.0>, <Variable path=huber_metric_1/count, shape=(), dtype=float32, value=0.0>]\n"
     ]
    }
   ],
   "source": [
    "m = HuberMetric(2.)\n",
    "print(\"\\nHuberMetric (update 1):\\n\", m(tf.constant([[2.]]), tf.constant([[10.]])) )\n",
    "print(\"HuberMetric (update 2):\\n\", m(tf.constant([[0.], [5.]]), tf.constant([[1.], [9.25]])))\n",
    "print(\"Hasil HuberMetric:\\n\", m.result())\n",
    "print(\"Variabel HuberMetric:\\n\", m.variables)\n",
    "m.reset_state()\n",
    "print(\"Variabel HuberMetric setelah reset:\\n\", m.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "78617b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menguji HuberMetric class pada model\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "550f01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "95a259c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan HuberMetric class:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 99ms/step - huber_metric: 1.3709 - loss: 1.3709\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 91ms/step - huber_metric: 0.2623 - loss: 0.2623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a600ba510>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n",
    "print(\"\\nMelatih model dengan HuberMetric class:\")\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f2c06ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model_with_custom_metric.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ce82ff1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melanjutkan pelatihan model yang dimuat dengan HuberMetric class:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 97ms/step - huber_metric_1: 0.2405 - loss: 0.2405\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 89ms/step - huber_metric_1: 0.2289 - loss: 0.2289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a30631040>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_custom_metric.keras\",\n",
    "    custom_objects={\n",
    "        \"HuberMetric\": HuberMetric,\n",
    "        \"huber_fn\": create_huber(2.0)\n",
    "    }\n",
    ")\n",
    "\n",
    "model.compile(loss=create_huber(2.0), optimizer=\"nadam\", metrics=[HuberMetric(2.0)])\n",
    "                                               \n",
    "print(\"\\nMelanjutkan pelatihan model yang dimuat dengan HuberMetric class:\")\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8374ef89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Daftar metrik:\n",
      "- loss: <class 'keras.src.metrics.reduction_metrics.Mean'>\n",
      "- compile_metrics: <class 'keras.src.trainers.compile_utils.CompileMetrics'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Daftar metrik:\")\n",
    "for m in model.metrics:\n",
    "    print(f\"- {m.name}: {type(m)}\")\n",
    "\n",
    "model.save(\"my_model_with_custom_metric.keras\")\n",
    "\n",
    "# Akses threshold metrik (perhatikan indeks mungkin berbeda tergantung versi TF)\n",
    "for metric in model.metrics:\n",
    "    if isinstance(metric, HuberMetric):\n",
    "        print(\"Threshold HuberMetric yang dimuat:\", metric.threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "80509344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versi HuberMetric yang lebih sederhana, subclass dari keras.metrics.Mean\n",
    "@register_keras_serializable()\n",
    "class HuberMetric(keras.metrics.Mean):\n",
    "    def __init__(self, threshold=1.0, name='HuberMetric', dtype=None):\n",
    "        self.threshold = threshold\n",
    "        self.huber_fn = create_huber(threshold)\n",
    "        super().__init__(name=name, dtype=dtype)\n",
    "        \n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        metric = self.huber_fn(y_true, y_pred)\n",
    "        super(HuberMetric, self).update_state(metric, sample_weight)\n",
    "        \n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"threshold\": self.threshold}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cfcf338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f650ae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"selu\", kernel_initializer=\"lecun_normal\",\n",
    "                       input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "450d48ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan HuberMetric (v2) dan weighted_metrics:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 102ms/step - HuberMetric: 1.4864 - loss: 0.7471\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 95ms/step - HuberMetric: 0.2579 - loss: 0.1271\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])\n",
    "print(\"\\nMelatih model dengan HuberMetric (v2) dan weighted_metrics:\")\n",
    "sample_weight = np.random.rand(len(y_train))\n",
    "history = model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32),\n",
    "                    epochs=2, sample_weight=sample_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a0b92f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loss epoch 0: 0.4256\n",
      "HuberMetric (metric) epoch 0: 0.8577\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nLoss epoch 0: {history.history['loss'][0]:.4f}\")\n",
    "print(f\"HuberMetric (metric) epoch 0: {history.history['HuberMetric'][0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0595b3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_metric_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3a197c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melanjutkan pelatihan model yang dimuat dengan HuberMetric (v2):\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - HuberMetric: 0.2365 - loss: 0.2365\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 95ms/step - HuberMetric: 0.2233 - loss: 0.2233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f4a3062e900>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = keras.models.load_model(\"my_model_with_a_custom_metric_v2.h5\")\n",
    "print(\"\\nMelanjutkan pelatihan model yang dimuat dengan HuberMetric (v2):\")\n",
    "model.compile(loss=keras.losses.Huber(2.0), optimizer=\"nadam\", weighted_metrics=[HuberMetric(2.0)])\n",
    "model.fit(X_train_scaled.astype(np.float32), y_train.astype(np.float32), epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "173cb33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in model.metrics:\n",
    "    if isinstance(metric, HuberMetric):\n",
    "        print(\"Threshold HuberMetric (v2) yang dimuat:\", metric.threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce0376a",
   "metadata": {},
   "source": [
    "#### Custom Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "22b11e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output exponential_layer untuk [-1., 0., 1.]:\n",
      " [0.36787948 1.         2.7182817 ]\n"
     ]
    }
   ],
   "source": [
    "# Membuat layer kustom.\n",
    "exponential_layer = keras.layers.Lambda(lambda x: tf.exp(x))\n",
    "input_tensor = tf.constant([-1., 0., 1.], dtype=tf.float32)\n",
    "\n",
    "print(\"\\nOutput exponential_layer untuk [-1., 0., 1.]:\\n\", exponential_layer(input_tensor).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2db2fe90",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4aa3986",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    keras.layers.Dense(1),\n",
    "    exponential_layer # Custom layer added at the end\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a62be0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan Exponential Layer:\n",
      "Epoch 1/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 0.9537 - val_loss: 0.8792\n",
      "Epoch 2/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 47ms/step - loss: 0.6431 - val_loss: 0.4506\n",
      "Epoch 3/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 39ms/step - loss: 0.4496 - val_loss: 0.3973\n",
      "Epoch 4/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 51ms/step - loss: 0.4116 - val_loss: 0.3648\n",
      "Epoch 5/5\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 46ms/step - loss: 0.4008 - val_loss: 0.3605\n",
      "\n",
      "Evaluasi model dengan Exponential Layer:\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.3810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.37481462955474854"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"sgd\")\n",
    "print(\"\\nMelatih model dengan Exponential Layer:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=5,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "print(\"\\nEvaluasi model dengan Exponential Layer:\")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7aa0db74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class MyDense kustom\n",
    "@register_keras_serializable()\n",
    "class MyDense(keras.layers.Layer):\n",
    "    def __init__(self, units, activation=None, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.activation = keras.activations.get(activation)\n",
    "\n",
    "    def build(self, batch_input_shape):\n",
    "        self.kernel = self.add_weight(\n",
    "            name=\"kernel\", shape=[batch_input_shape[-1], self.units],\n",
    "            initializer=\"glorot_normal\")\n",
    "        self.bias = self.add_weight(\n",
    "            name=\"bias\", shape=[self.units], initializer=\"zeros\")\n",
    "        super().build(batch_input_shape) # Must be at the end of build\n",
    "\n",
    "    def call(self, X):\n",
    "        return self.activation(X @ self.kernel + self.bias)\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return tf.TensorShape(batch_input_shape[:-1] + (self.units,))\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super().get_config()\n",
    "        return {**base_config, \"units\": self.units,\n",
    "                \"activation\": keras.activations.serialize(self.activation)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e3855782",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2a779401",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230925/1644174987.py:5: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    MyDense(30, activation=\"relu\", input_shape=input_shape),\n",
    "    MyDense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d91cb34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan MyDense custom layer:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 95ms/step - loss: 0.5318 - val_loss: 2.0399\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 95ms/step - loss: 0.4257 - val_loss: 0.4713\n",
      "\n",
      "Evaluasi model dengan MyDense custom layer:\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 22ms/step - loss: 0.4094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4058610796928406"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.losses import MeanSquaredError\n",
    "\n",
    "model.compile(loss=MeanSquaredError(), optimizer=\"nadam\")\n",
    "print(\"\\nMelatih model dengan MyDense custom layer:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "print(\"\\nEvaluasi model dengan MyDense custom layer:\")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "86c1ae23",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save(\"my_model_with_a_custom_layer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "462b9c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\n",
    "    \"my_model_with_a_custom_layer.h5\",\n",
    "    custom_objects={\n",
    "        \"MyDense\": MyDense,\n",
    "        \"mse\": MeanSquaredError()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "557c38ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class MyMultiLayer kustom (menghasilkan banyak output)\n",
    "@register_keras_serializable()\n",
    "class MyMultiLayer(keras.layers.Layer):\n",
    "    def call(self, X):\n",
    "        X1, X2 = X\n",
    "        print(\"X1.shape: \", X1.shape ,\" X2.shape: \", X2.shape) # Debugging\n",
    "        return X1 + X2, X1 * X2\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        batch_input_shape1, batch_input_shape2 = batch_input_shape\n",
    "        return [batch_input_shape1, batch_input_shape2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a3732a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Penggunaan MyMultiLayer dengan Functional API\n",
    "inputs1 = keras.layers.Input(shape=[2])\n",
    "inputs2 = keras.layers.Input(shape=[2])\n",
    "outputs1, outputs2 = MyMultiLayer()((inputs1, inputs2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "4037c336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bentuk X_train_scaled_A: (11610, 4), Bentuk X_train_scaled_B: (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "# Memisahkan data untuk input multi-layer\n",
    "def split_data(data):\n",
    "    columns_count = data.shape[-1]\n",
    "    half = columns_count // 2\n",
    "    return data[:, :half], data[:, half:]\n",
    "\n",
    "X_train_scaled_A, X_train_scaled_B = split_data(X_train_scaled)\n",
    "X_valid_scaled_A, X_valid_scaled_B = split_data(X_valid_scaled)\n",
    "X_test_scaled_A, X_test_scaled_B = split_data(X_test_scaled)\n",
    "\n",
    "print(f\"\\nBentuk X_train_scaled_A: {X_train_scaled_A.shape}, Bentuk X_train_scaled_B: {X_train_scaled_B.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1854e8d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X1.shape:  (11610, 4)  X2.shape:  (11610, 4)\n"
     ]
    }
   ],
   "source": [
    "# Panggilan dengan data aktual (shape akan sepenuhnya ditentukan)\n",
    "outputs1, outputs2 = MyMultiLayer()((X_train_scaled_A, X_train_scaled_B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7b2806ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membangun model dengan MyMultiLayer\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d9ac9770",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_A = keras.layers.Input(shape=X_train_scaled_A.shape[-1:])\n",
    "input_B = keras.layers.Input(shape=X_train_scaled_B.shape[-1:])\n",
    "hidden_A, hidden_B = MyMultiLayer()((input_A, input_B))\n",
    "hidden_A = keras.layers.Dense(30, activation='selu')(hidden_A)\n",
    "hidden_B = keras.layers.Dense(30, activation='selu')(hidden_B)\n",
    "concat = keras.layers.Concatenate()((hidden_A, hidden_B))\n",
    "output = keras.layers.Dense(1)(concat)\n",
    "model = keras.models.Model(inputs=[input_A, input_B], outputs=[output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "adce6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan MyMultiLayer:\n",
      "Epoch 1/2\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  1/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:07\u001b[0m 186ms/step - loss: 3.0163X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  2/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 140ms/step - loss: 3.2335 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  3/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m56s\u001b[0m 156ms/step - loss: 3.1325X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  4/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 153ms/step - loss: 3.0986X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  5/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 153ms/step - loss: 3.1081X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  6/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m50s\u001b[0m 140ms/step - loss: 3.1149X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  7/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 132ms/step - loss: 3.1227X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  8/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 125ms/step - loss: 3.1193X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  9/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 120ms/step - loss: 3.1161X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 10/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 119ms/step - loss: 3.1106X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 11/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 115ms/step - loss: 3.1016X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 12/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 112ms/step - loss: 3.0908X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 13/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 109ms/step - loss: 3.0782X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 14/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 108ms/step - loss: 3.0664X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 15/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 108ms/step - loss: 3.0540X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 16/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 107ms/step - loss: 3.0445X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 17/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 3.0331X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 18/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 108ms/step - loss: 3.0226X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 19/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 109ms/step - loss: 3.0141X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 20/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 108ms/step - loss: 3.0068X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 21/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 2.9984X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 22/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 108ms/step - loss: 2.9929X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 23/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 107ms/step - loss: 2.9867X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 24/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 106ms/step - loss: 2.9805X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 25/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 2.9745X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 26/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 106ms/step - loss: 2.9680X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 27/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 105ms/step - loss: 2.9615X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 28/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 104ms/step - loss: 2.9552X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 29/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 104ms/step - loss: 2.9487X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 30/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 104ms/step - loss: 2.9424X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 31/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - loss: 2.9358X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 32/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - loss: 2.9290X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 33/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 105ms/step - loss: 2.9219X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 34/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 104ms/step - loss: 2.9149X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 35/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 104ms/step - loss: 2.9080X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 36/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.9010X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 37/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 104ms/step - loss: 2.8936X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 38/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.8858X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 39/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.8781X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 40/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 104ms/step - loss: 2.8702X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 41/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.8622X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 42/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.8551X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 43/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 2.8475X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 44/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.8396X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 45/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.8313X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 46/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.8231X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 47/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.8149X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 48/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.8065X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 49/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.7985X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 50/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 2.7902X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 51/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7823X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 52/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7743X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 53/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7665X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 54/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7585X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 55/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7503X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 56/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 2.7422X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 57/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 2.7343X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 58/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 2.7262X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 59/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 2.7180X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 60/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.7101X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 61/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.7023X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 62/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 2.6944X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 63/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.6865X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 64/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.6787X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 65/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.6710X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 66/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.6633X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 67/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 102ms/step - loss: 2.6556X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 68/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6480X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 69/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6405X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 70/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6332X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 71/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6258X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 72/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6184X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 73/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 102ms/step - loss: 2.6111X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 74/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 143ms/step - loss: 2.6039X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 75/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m41s\u001b[0m 142ms/step - loss: 2.5967X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 76/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 142ms/step - loss: 2.5894X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 77/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - loss: 2.5823X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 78/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m40s\u001b[0m 141ms/step - loss: 2.5752X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 79/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5681X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 80/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5610X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 81/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5540X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 82/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5470X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 83/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5400X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 84/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 140ms/step - loss: 2.5330X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 85/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 140ms/step - loss: 2.5261X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 86/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 139ms/step - loss: 2.5191X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 87/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 139ms/step - loss: 2.5121X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 88/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 139ms/step - loss: 2.5052X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 89/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m38s\u001b[0m 139ms/step - loss: 2.4984X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 90/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 138ms/step - loss: 2.4916X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 91/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 138ms/step - loss: 2.4849X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 92/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 138ms/step - loss: 2.4783X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 93/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 137ms/step - loss: 2.4717X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 94/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 137ms/step - loss: 2.4651X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 95/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 136ms/step - loss: 2.4586X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 96/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 136ms/step - loss: 2.4521X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 97/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 136ms/step - loss: 2.4458X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 98/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 136ms/step - loss: 2.4395X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 99/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 135ms/step - loss: 2.4333X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m100/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 135ms/step - loss: 2.4273X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m101/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 134ms/step - loss: 2.4214X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m102/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 134ms/step - loss: 2.4156X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m103/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 134ms/step - loss: 2.4098X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m104/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 134ms/step - loss: 2.4041X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m105/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 134ms/step - loss: 2.3984X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m106/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 133ms/step - loss: 2.3928X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m107/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 133ms/step - loss: 2.3871X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m108/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 133ms/step - loss: 2.3815X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m109/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - loss: 2.3759X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m110/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - loss: 2.3703X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m111/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - loss: 2.3647X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m112/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 132ms/step - loss: 2.3592X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m113/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 131ms/step - loss: 2.3538X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m114/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 131ms/step - loss: 2.3484X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m115/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 131ms/step - loss: 2.3431X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m116/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 130ms/step - loss: 2.3378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m117/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - loss: 2.3325X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m118/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 130ms/step - loss: 2.3272X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m119/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 129ms/step - loss: 2.3220X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m120/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 129ms/step - loss: 2.3169X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m121/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 129ms/step - loss: 2.3117X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m122/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - loss: 2.3066X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m123/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - loss: 2.3015X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m124/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - loss: 2.2964X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m125/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - loss: 2.2914X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m126/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 128ms/step - loss: 2.2863X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m127/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 127ms/step - loss: 2.2813X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m128/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2763X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m129/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2714X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m130/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2664X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m131/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2615X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m132/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2567X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m133/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 127ms/step - loss: 2.2519X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m134/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 127ms/step - loss: 2.2470X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m135/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2423X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m136/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2375X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m137/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2328X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m138/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2282X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m139/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2235X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m140/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 126ms/step - loss: 2.2190X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m141/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.2144X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m142/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.2100X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m143/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.2055X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m144/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.2011X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m145/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.1966X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m146/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 125ms/step - loss: 2.1923X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m147/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 125ms/step - loss: 2.1880X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m148/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - loss: 2.1877X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m149/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - loss: 2.1874X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m150/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - loss: 2.1871X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m151/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 124ms/step - loss: 2.1867X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m152/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 123ms/step - loss: 2.1863X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m153/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - loss: 2.1858X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m154/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - loss: 2.1853X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m155/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - loss: 2.1848X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m156/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - loss: 2.1842X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m157/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 123ms/step - loss: 2.1835X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m158/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 122ms/step - loss: 2.1829X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m159/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - loss: 2.1823X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m160/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - loss: 2.1816X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m161/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - loss: 2.1809X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m162/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - loss: 2.1802X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m163/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 122ms/step - loss: 2.1794X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m164/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 121ms/step - loss: 2.1786X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m165/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1778X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m166/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1769X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m167/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1760X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m168/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1751X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m169/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1742X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m170/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1733X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m171/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1723X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m172/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 121ms/step - loss: 2.1713X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m173/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - loss: 2.1703X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m174/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 121ms/step - loss: 2.1692X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m175/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 2.1682X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m176/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 2.1671X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m177/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 2.1660X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m178/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 2.1649X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m179/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 120ms/step - loss: 2.1638X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m180/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1626X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m181/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1614X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m182/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1603X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m183/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1591X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m184/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1579X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m185/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1566X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m186/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1554X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m187/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 120ms/step - loss: 2.1541X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m188/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 120ms/step - loss: 2.1529X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m189/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1516X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m190/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1503X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m191/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1490X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m192/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1477X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m193/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1464X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m194/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 119ms/step - loss: 2.1450X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m195/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1437X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m196/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1423X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m197/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1410X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m198/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1396X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m199/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m200/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1368X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m201/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1354X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m202/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1340X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m203/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 119ms/step - loss: 2.1326X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m204/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 119ms/step - loss: 2.1312X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m205/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 119ms/step - loss: 2.1298X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m206/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - loss: 2.1284X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m207/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - loss: 2.1269X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m208/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - loss: 2.1255X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m209/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - loss: 2.1240X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m210/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 118ms/step - loss: 2.1226X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m211/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1211X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m212/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1196X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m213/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1182X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m214/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1167X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m215/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1153X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m216/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1138X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m217/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1124X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m218/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 118ms/step - loss: 2.1110X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m219/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1096X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m220/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1081X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m221/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1067X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m222/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1052X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m223/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1038X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m224/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1024X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m225/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.1009X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m226/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.0995X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m227/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 118ms/step - loss: 2.0981X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m228/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0967X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m229/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0952X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m230/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0938X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m231/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0923X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m232/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0909X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m233/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0894X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m234/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0880X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m235/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 118ms/step - loss: 2.0865X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m236/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 2.0851X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m237/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 118ms/step - loss: 2.0836X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m238/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0822X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m239/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0807X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m240/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0792X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m241/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0777X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m242/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0763X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m243/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 117ms/step - loss: 2.0748X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m244/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.0733X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m245/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.0718X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m246/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.0703X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m247/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 117ms/step - loss: 2.0688X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m248/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0673X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m249/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0658X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m250/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0643X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m251/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 116ms/step - loss: 2.0628X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m252/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0612X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m253/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0597X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m254/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0582X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m255/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0567X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m256/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0552X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m257/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0536X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m258/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0521X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m259/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 116ms/step - loss: 2.0506X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m260/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - loss: 2.0491X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m261/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - loss: 2.0475X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m262/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 116ms/step - loss: 2.0460X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m263/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 2.0445X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m264/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 2.0430X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m265/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 2.0415X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m266/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 2.0399X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m267/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 115ms/step - loss: 2.0384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m268/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0369X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m269/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0354X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m270/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0339X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m271/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0324X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m272/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0309X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m273/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0294X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m274/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0279X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m275/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0264X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m276/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m10s\u001b[0m 115ms/step - loss: 2.0249X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m277/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0235 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m278/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0220X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m279/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0205X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m280/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0190X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m281/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0175X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m282/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0161X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m283/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0146X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m284/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 115ms/step - loss: 2.0131X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m285/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0117X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m286/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0102X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m287/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0087X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m288/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0073X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m289/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0058X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m290/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0044X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m291/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0029X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m292/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0015X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m293/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m8s\u001b[0m 115ms/step - loss: 2.0000X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m294/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 1.9986X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m295/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9972X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m296/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9958X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m297/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9943X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m298/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9929X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m299/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9915X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m300/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9901X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m301/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.9887X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m302/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9873X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m303/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9859X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m304/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9845X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m305/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9831X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m306/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9817X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m307/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9804X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m308/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9790X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m309/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9776X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m310/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.9763X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m311/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9749X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m312/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9735X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m313/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9722X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m314/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9708X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m315/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9695X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m316/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9681X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m317/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9668X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m318/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9654X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m319/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.9641X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m320/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9628X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m321/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9615X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m322/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9601X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m323/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9588X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m324/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9575X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m325/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 114ms/step - loss: 1.9562X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m326/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.9549X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m327/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.9536X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m328/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9523X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m329/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9510X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m330/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9497X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m331/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9484X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m332/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9471X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m333/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9458X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m334/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9446X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m335/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9433X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m336/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.9420X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m337/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9407X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m338/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9395X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m339/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m340/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9369X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m341/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9356X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m342/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9344X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m343/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9331X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m344/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9319X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m345/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.9306X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m346/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.9293X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m347/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9281X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m348/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9268X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m349/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9256X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9244X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9231X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9219X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9207X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.9194X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9182X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9170X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9158X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9146X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9134X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9121X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m361/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9109X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9097X1.shape:  (26, 4)  X2.shape:  (26, 4)\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.9086X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (30, 4)  X2.shape:  (30, 4)\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 129ms/step - loss: 1.9074 - val_loss: 8.9940\n",
      "Epoch 2/2\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  1/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m47s\u001b[0m 130ms/step - loss: 0.6216X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  2/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - loss: 0.7646X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  3/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m42s\u001b[0m 119ms/step - loss: 0.7634X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  4/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 111ms/step - loss: 0.7683X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  5/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 104ms/step - loss: 0.7782X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  6/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - loss: 0.7729X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  7/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - loss: 0.7819X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  8/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 101ms/step - loss: 0.7817X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m  9/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m37s\u001b[0m 105ms/step - loss: 0.7800X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 10/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 104ms/step - loss: 0.7807X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 11/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 101ms/step - loss: 0.7812X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 12/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 102ms/step - loss: 0.7830X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 13/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 103ms/step - loss: 0.7879X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 14/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m36s\u001b[0m 103ms/step - loss: 0.7971X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 15/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 102ms/step - loss: 0.8038X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 16/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m35s\u001b[0m 101ms/step - loss: 0.8102X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 17/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - loss: 0.8155X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 18/363\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - loss: 0.8198X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 19/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - loss: 0.8235X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 20/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 99ms/step - loss: 0.8273 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 21/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - loss: 0.8306X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 22/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 99ms/step - loss: 0.8327X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 23/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 100ms/step - loss: 0.8361X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 24/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 101ms/step - loss: 0.8397X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 25/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.8435X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 26/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.8469X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 27/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - loss: 0.8507X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 28/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 104ms/step - loss: 0.8537X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 29/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.8563X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 30/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 102ms/step - loss: 0.8584X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 31/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 103ms/step - loss: 0.8602X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 32/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8623X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 33/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8645X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 34/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 103ms/step - loss: 0.8666X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 35/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8688X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 36/363\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8715X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 37/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8740X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 38/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m33s\u001b[0m 102ms/step - loss: 0.8761X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 39/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - loss: 0.8779X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 40/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - loss: 0.8796X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 41/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - loss: 0.8817X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 42/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 101ms/step - loss: 0.8835X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 43/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 0.8853X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 44/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 103ms/step - loss: 0.8871X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 45/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - loss: 0.8886X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 46/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 101ms/step - loss: 0.8900X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 47/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m32s\u001b[0m 102ms/step - loss: 0.8916X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 48/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - loss: 0.8933X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 49/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 101ms/step - loss: 0.8948X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 50/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.8963X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 51/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.8976X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 52/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.8990X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 53/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.9003X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 54/363\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.9016X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 55/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.9027X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 56/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m31s\u001b[0m 102ms/step - loss: 0.9039X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 57/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 0.9050X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 58/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 0.9062X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 59/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 0.9073X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 60/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 101ms/step - loss: 0.9082X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 61/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - loss: 0.9091X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 62/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m30s\u001b[0m 100ms/step - loss: 0.9100X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 63/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9108X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 64/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9115X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 65/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9121X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 66/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9126X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 67/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9131X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 68/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 101ms/step - loss: 0.9136X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 69/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9141X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 70/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9146X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 71/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 100ms/step - loss: 0.9150X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 72/363\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 100ms/step - loss: 0.9155X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 73/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9161 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 74/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9236X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 75/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9308X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 76/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9377X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 77/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9444X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 78/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9508X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 79/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9570X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 80/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m28s\u001b[0m 99ms/step - loss: 0.9628X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 81/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9685X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 82/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9740X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 83/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9793X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 84/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9845X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 85/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9894X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 86/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9943X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 87/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 0.9990X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 88/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 98ms/step - loss: 1.0034X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 89/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 99ms/step - loss: 1.0078X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 90/363\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - loss: 1.0119X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 91/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - loss: 1.0159X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 92/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - loss: 1.0198X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 93/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 98ms/step - loss: 1.0235X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 94/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0271X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 95/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0305X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 96/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0338X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 97/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0371X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 98/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0403X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m 99/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 99ms/step - loss: 1.0433X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m100/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 100ms/step - loss: 1.0463X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m101/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m26s\u001b[0m 100ms/step - loss: 1.0491X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m102/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 99ms/step - loss: 1.0518 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m103/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0544X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m104/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0570X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m105/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0594X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m106/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0618X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m107/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0642X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m108/363\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0666X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m109/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0688X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m110/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0710X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m111/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0732X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m112/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m25s\u001b[0m 100ms/step - loss: 1.0753X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m113/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0773X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m114/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0793X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m115/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0813X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m116/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0831X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m117/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0849X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m118/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0867X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m119/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0884X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m120/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0901X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m121/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0917X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m122/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m24s\u001b[0m 100ms/step - loss: 1.0933X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m123/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.0948X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m124/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - loss: 1.0964 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m125/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - loss: 1.0978X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m126/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 99ms/step - loss: 1.0993X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m127/363\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.1006X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m128/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.1019X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m129/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.1031X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m130/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.1044X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m131/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 100ms/step - loss: 1.1055X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m132/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 1.1066X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m133/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 1.1077X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m134/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m23s\u001b[0m 101ms/step - loss: 1.1088X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m135/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 100ms/step - loss: 1.1099X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m136/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1109X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m137/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1119X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m138/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1129X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m139/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1138X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m140/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1147X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m141/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1156X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m142/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1164X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m143/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1172X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m144/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1180X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m145/363\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 101ms/step - loss: 1.1188X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m146/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 102ms/step - loss: 1.1195X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m147/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 102ms/step - loss: 1.1202X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m148/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - loss: 1.1209X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m149/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 102ms/step - loss: 1.1216X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m150/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - loss: 1.1222X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m151/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - loss: 1.1228X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m152/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 103ms/step - loss: 1.1234X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m153/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1240X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m154/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1246X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m155/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1251X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m156/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1256X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m157/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1261X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m158/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1266X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m159/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1270X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m160/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1274X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m161/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 104ms/step - loss: 1.1279X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m162/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 104ms/step - loss: 1.1283X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m163/363\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - loss: 1.1287X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m164/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - loss: 1.1291X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m165/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - loss: 1.1295X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m166/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1298X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m167/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1302X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m168/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1305X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m169/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 105ms/step - loss: 1.1309X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m170/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1312X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m171/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1315X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m172/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1318X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m173/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1321X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m174/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 106ms/step - loss: 1.1324X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m175/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1326X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m176/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1329X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m177/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1331X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m178/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1334X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m179/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1336X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m180/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1338X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m181/363\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1341X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m182/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1343X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m183/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m19s\u001b[0m 106ms/step - loss: 1.1345X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m184/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1348X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m185/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1350X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m186/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1353X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m187/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1355X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m188/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1357X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m189/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1359X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m190/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1361X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m191/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1362X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m192/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1364X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m193/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m18s\u001b[0m 106ms/step - loss: 1.1365X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m194/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1366X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m195/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1368X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m196/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1369X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m197/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1370X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m198/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1371X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m199/363\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1372X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m200/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 105ms/step - loss: 1.1373X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m201/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 106ms/step - loss: 1.1374X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m202/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1374X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m203/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1375X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m204/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1376X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m205/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1376X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m206/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1377X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m207/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1377X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m208/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m209/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m210/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1379X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m211/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m16s\u001b[0m 106ms/step - loss: 1.1380X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m212/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1380X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m213/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1381X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m214/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1381X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m215/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m216/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m217/363\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m218/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m219/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m220/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m221/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m15s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m222/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m223/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m224/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m225/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m226/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m227/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m228/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m229/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m230/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m231/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m232/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1384X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m233/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m234/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m235/363\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m236/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1383X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m237/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m238/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1382X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m239/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - loss: 1.1381X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m240/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.1381X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m241/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1380X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m242/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1380X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m243/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1379X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m244/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1379X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m245/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m246/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 106ms/step - loss: 1.1378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m247/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1378X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m248/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1377X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m249/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - loss: 1.1377X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m250/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1376X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m251/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1375X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m252/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1375X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m253/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1374X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m254/363\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1373X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m255/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1373X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m256/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1372X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m257/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1371X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m258/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 105ms/step - loss: 1.1370X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m259/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1369X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m260/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1369X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m261/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1368X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m262/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1367X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m263/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1366X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m264/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1365X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m265/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1364X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m266/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1363X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m267/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 105ms/step - loss: 1.1362X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m268/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1361 X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m269/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1360X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m270/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1359X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m271/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1358X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m272/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1357X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m273/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1356X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m274/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1355X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m275/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1354X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m276/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m9s\u001b[0m 105ms/step - loss: 1.1352X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m277/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 105ms/step - loss: 1.1351X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m278/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1350X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m279/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1349X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m280/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1347X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m281/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1346X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m282/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1345X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m283/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1344X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m284/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1343X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m285/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1342X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m286/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m8s\u001b[0m 104ms/step - loss: 1.1340X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m287/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1339X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m288/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1338X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m289/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1337X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m290/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1336X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m291/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1334X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m292/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1333X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m293/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1332X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m294/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1330X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m295/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 104ms/step - loss: 1.1329X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m296/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 1.1328X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m297/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 1.1326X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m298/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 1.1325X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m299/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - loss: 1.1324X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m300/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.1323X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m301/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - loss: 1.1321X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m302/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1320X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m303/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1319X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m304/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1318X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m305/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1316X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m306/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1315X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m307/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1314X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m308/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1313X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m309/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1312X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m310/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m6s\u001b[0m 114ms/step - loss: 1.1310X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m311/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.1309X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m312/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 114ms/step - loss: 1.1308X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m313/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1307X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m314/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1306X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m315/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1304X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m316/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1303X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m317/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1302X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m318/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - loss: 1.1301X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m319/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1299X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m320/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1298X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m321/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1297X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m322/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1296X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m323/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1295X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m324/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1293X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m325/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1292X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m326/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1291X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m327/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m4s\u001b[0m 113ms/step - loss: 1.1289X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m328/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1288X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m329/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1287X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m330/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1285X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m331/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1284X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m332/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1282X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m333/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1281X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m334/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1280X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m335/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1278X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m336/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m3s\u001b[0m 113ms/step - loss: 1.1277X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m337/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1275X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m338/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1274X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m339/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1273X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m340/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1271X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m341/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1270X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m342/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1268X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m343/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1267X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m344/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1266X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m345/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m2s\u001b[0m 113ms/step - loss: 1.1264X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m346/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1263X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m347/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1261X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m348/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1260X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m349/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1258X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m350/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1257X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m351/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 113ms/step - loss: 1.1255X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m352/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1254X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m353/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1252X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m354/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m1s\u001b[0m 112ms/step - loss: 1.1251X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m355/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1249X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m356/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1248X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m357/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1246X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m358/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1245X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m359/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1243X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m360/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1242X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m361/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1240X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "\u001b[1m362/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1239X1.shape:  (26, 4)  X2.shape:  (26, 4)\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 1.1237X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (32, 4)  X2.shape:  (32, 4)\n",
      "X1.shape:  (30, 4)  X2.shape:  (30, 4)\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 120ms/step - loss: 1.1236 - val_loss: 3.1905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f49d94f5dc0>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=MeanSquaredError(), optimizer=\"nadam\")\n",
    "print(\"\\nMelatih model dengan MyMultiLayer:\")\n",
    "model.fit((X_train_scaled_A, X_train_scaled_B), y_train, epochs=2,\n",
    "          validation_data=((X_valid_scaled_A, X_valid_scaled_B), y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "be4be505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layer dengan perilaku berbeda selama training dan testing\n",
    "@register_keras_serializable()\n",
    "class AddGaussianNoise(keras.layers.Layer):\n",
    "    def __init__(self, stddev, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.stddev = stddev\n",
    "\n",
    "    def call(self, X, training=None):\n",
    "        if training:\n",
    "            noise = tf.random.normal(tf.shape(X), stddev=self.stddev)\n",
    "            return X + noise\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def compute_output_shape(self, batch_input_shape):\n",
    "        return batch_input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "7eb9c647",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "008ef5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_230925/4085291381.py:5: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    AddGaussianNoise(stddev=1.0, input_shape=input_shape), # Add input_shape to the first layer\n",
    "    keras.layers.Dense(30, activation=\"selu\"),\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "dc6d0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan AddGaussianNoise layer:\n",
      "Epoch 1/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 95ms/step - loss: 3.4236 - val_loss: 1.4222\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 96ms/step - loss: 1.0115 - val_loss: 0.7626\n",
      "\n",
      "Evaluasi model dengan AddGaussianNoise layer:\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - loss: 0.7829\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.779594361782074"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "print(\"\\nMelatih model dengan AddGaussianNoise layer:\")\n",
    "model.fit(X_train_scaled, y_train, epochs=2,\n",
    "          validation_data=(X_valid_scaled, y_valid))\n",
    "print(\"\\nEvaluasi model dengan AddGaussianNoise layer:\")\n",
    "model.evaluate(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbff039",
   "metadata": {},
   "source": [
    "#### Custom Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "337b68a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model kustom dengan subclassing `keras.models.Model`.\n",
    "X_new_scaled = X_test_scaled # Menggunakan X_test_scaled untuk prediksi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "fb5392fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual Block untuk model kustom\n",
    "@register_keras_serializable()\n",
    "class ResidualBlock(keras.layers.Layer):\n",
    "    def __init__(self, n_layers, n_neurons, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(n_neurons, activation=\"elu\",\n",
    "                                          kernel_initializer=\"he_normal\")\n",
    "                       for _ in range(n_layers)]\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return inputs + Z # Add input to output (skip connection)\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"n_layers\": len(self.hidden), \"n_neurons\": self.hidden[0].units})\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "532efaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ResidualRegressor kustom\n",
    "@register_keras_serializable()\n",
    "class ResidualRegressor(keras.models.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.output_dim = output_dim\n",
    "        self.hidden1 = keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\")\n",
    "        self.block1 = ResidualBlock(2, 30)\n",
    "        self.block2 = ResidualBlock(2, 30)\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        Z = self.hidden1(inputs)\n",
    "        for _ in range(4):\n",
    "            Z = self.block1(Z)\n",
    "        Z = self.block2(Z)\n",
    "        return self.out(Z)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\"output_dim\": self.output_dim})\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        output_dim = config.pop(\"output_dim\")\n",
    "        return cls(output_dim=output_dim, **config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "160bac4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "842dd760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih Custom ResidualRegressor model:\n",
      "Epoch 1/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 229ms/step - loss: 27.5502\n",
      "Epoch 2/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 224ms/step - loss: 3.8500\n",
      "Epoch 3/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 227ms/step - loss: 1.7384\n",
      "Epoch 4/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 243ms/step - loss: 0.7171\n",
      "\n",
      "Evaluasi Custom ResidualRegressor model:\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - loss: 7.2644\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 24ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ResidualRegressor(1)\n",
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "print(\"\\nMelatih Custom ResidualRegressor model:\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=4) # Mengurangi epoch jika terlalu lama\n",
    "print(\"\\nEvaluasi Custom ResidualRegressor model:\")\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "43579919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melanjutkan pelatihan model kustom yang dimuat:\n",
      "Epoch 1/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 217ms/step - loss: 2.4661\n",
      "Epoch 2/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 254ms/step - loss: 0.5768\n",
      "Epoch 3/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 228ms/step - loss: 0.8610\n",
      "Epoch 4/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 222ms/step - loss: 0.5564\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan dan memuat model kustom (format SavedModel direkomendasikan)\n",
    "model.save(\"my_custom_model.keras\")\n",
    "model = keras.models.load_model(\"my_custom_model.keras\")\n",
    "print(\"\\nMelanjutkan pelatihan model kustom yang dimuat:\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=4) # Mengurangi epoch jika terlalu lama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "85a10c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model kustom menggunakan Sequential API (jika memungkinkan)\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "d5d98759",
   "metadata": {},
   "outputs": [],
   "source": [
    "block1 = ResidualBlock(2, 30)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\"),\n",
    "    block1, block1, block1, block1, # Menggunakan instance block yang sama empat kali\n",
    "    ResidualBlock(2, 30), # Instance block yang berbeda\n",
    "    keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "46d1a6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih model dengan ResidualBlock menggunakan Sequential API:\n",
      "Epoch 1/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 207ms/step - loss: 15.2378\n",
      "Epoch 2/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 221ms/step - loss: 1.3766\n",
      "Epoch 3/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 219ms/step - loss: 0.7080\n",
      "Epoch 4/4\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 207ms/step - loss: 0.5971\n",
      "\n",
      "Evaluasi model dengan ResidualBlock menggunakan Sequential API:\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 41ms/step - loss: 0.9657\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"nadam\")\n",
    "print(\"\\nMelatih model dengan ResidualBlock menggunakan Sequential API:\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=4) # Mengurangi epoch\n",
    "print(\"\\nEvaluasi model dengan ResidualBlock menggunakan Sequential API:\")\n",
    "score = model.evaluate(X_test_scaled, y_test)\n",
    "y_pred = model.predict(X_new_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072af06",
   "metadata": {},
   "source": [
    "#### Losses and Metrics Based on Model Internals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ee84bbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat model dengan loss dan metrik yang bergantung pada internal model (misalnya, rekonstruksi loss).\n",
    "class ReconstructingRegressor(keras.Model):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hidden = [keras.layers.Dense(30, activation=\"selu\",\n",
    "                                          kernel_initializer=\"lecun_normal\")\n",
    "                       for _ in range(5)]\n",
    "        self.out = keras.layers.Dense(output_dim)\n",
    "        self.reconstruction_mean = keras.metrics.Mean(name=\"reconstruction_error\")\n",
    "        self.loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "        self.mae_metric = keras.metrics.MeanAbsoluteError(name=\"mae\")\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        n_inputs = input_shape[-1]\n",
    "        self.reconstruct = keras.layers.Dense(n_inputs)\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        Z = inputs\n",
    "        for layer in self.hidden:\n",
    "            Z = layer(Z)\n",
    "        return self.out(Z), self.reconstruct(Z)\n",
    "\n",
    "    def train_step(self, data):\n",
    "        X, y = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred, reconstruction = self(X, training=True)\n",
    "            main_loss = self.compiled_loss(y, y_pred)\n",
    "            recon_loss = tf.reduce_mean(tf.square(reconstruction - X))\n",
    "            total_loss = main_loss + 0.05 * recon_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_variables))\n",
    "        self.reconstruction_mean.update_state(recon_loss)\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.mae_metric.update_state(y, y_pred)\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"mae\": self.mae_metric.result(),\n",
    "            \"reconstruction_error\": self.reconstruction_mean.result()\n",
    "        }\n",
    "\n",
    "    def test_step(self, data):\n",
    "        X, y = data\n",
    "        y_pred, reconstruction = self(X, training=False)\n",
    "        main_loss = self.compiled_loss(y, y_pred)\n",
    "        recon_loss = tf.reduce_mean(tf.square(reconstruction - X))\n",
    "        total_loss = main_loss + 0.05 * recon_loss\n",
    "        self.reconstruction_mean.update_state(recon_loss)\n",
    "        self.loss_tracker.update_state(total_loss)\n",
    "        self.mae_metric.update_state(y, y_pred)\n",
    "        return {\n",
    "            \"loss\": self.loss_tracker.result(),\n",
    "            \"mae\": self.mae_metric.result(),\n",
    "            \"reconstruction_error\": self.reconstruction_mean.result()\n",
    "        }\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_tracker, self.mae_metric, self.reconstruction_mean]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "64b7f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "36cf45bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Melatih ReconstructingRegressor model:\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ardi/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:665: UserWarning: `model.compiled_loss()` is deprecated. Instead, use `model.compute_loss(x, y, y_pred, sample_weight, training)`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 229ms/step - loss: 1.0959 - mae: 0.7285 - reconstruction_error: 1.6768\n",
      "Epoch 2/2\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 237ms/step - loss: 0.4265 - mae: 0.4605 - reconstruction_error: 0.4655\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step\n"
     ]
    }
   ],
   "source": [
    "model = ReconstructingRegressor(1)\n",
    "model.build((None, X_train_scaled.shape[1]))\n",
    "model.compile(optimizer=\"nadam\", loss=\"mse\")\n",
    "\n",
    "print(\"\\nMelatih ReconstructingRegressor model:\")\n",
    "history = model.fit(X_train_scaled, y_train, epochs=2)\n",
    "\n",
    "y_pred, _ = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758b0220",
   "metadata": {},
   "source": [
    "#### Computing Gradients with Autodiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "76581e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menghitung gradien menggunakan Automatic Differentiation (Autodiff) TensorFlow.\n",
    "def f(w1, w2):\n",
    "    return 3 * w1 ** 2 + 2 * w1 * w2\n",
    "\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "cb5f0ac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien z terhadap [w1, w2]:\n",
      " [<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
     ]
    }
   ],
   "source": [
    "# Menghitung gradien\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(w1, w2)\n",
    "gradients = tape.gradient(z, [w1, w2])\n",
    "print(\"\\nGradien z terhadap [w1, w2]:\\n\", gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "c3197c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien z terhadap w1: tf.Tensor(36.0, shape=(), dtype=float32)\n",
      "Gradien z terhadap w2: tf.Tensor(10.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Menghitung gradien secara terpisah (membutuhkan persistent=True)\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z = f(w1, w2)\n",
    "dz_dw1 = tape.gradient(z, w1)\n",
    "dz_dw2 = tape.gradient(z, w2) # Sekarang berfungsi\n",
    "del tape\n",
    "print(\"\\nGradien z terhadap w1:\", dz_dw1)\n",
    "print(\"Gradien z terhadap w2:\", dz_dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "02321143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien z terhadap [c1, c2] (tanpa watch, akan None):\n",
      " [None, None]\n"
     ]
    }
   ],
   "source": [
    "# Gradien untuk konstanta (defaultnya None, harus di-watch)\n",
    "c1, c2 = tf.constant(5.), tf.constant(3.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = f(c1, c2)\n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "print(\"\\nGradien z terhadap [c1, c2] (tanpa watch, akan None):\\n\", gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "857345d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien z terhadap [c1, c2] (dengan watch):\n",
      " [<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(c1)\n",
    "    tape.watch(c2)\n",
    "    z = f(c1, c2)\n",
    "gradients = tape.gradient(z, [c1, c2])\n",
    "print(\"\\nGradien z terhadap [c1, c2] (dengan watch):\\n\", gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "c90f6e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien total dari [z1, z2, z3] terhadap [w1, w2]:\n",
      " tf.Tensor([136.  30.], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Gradien dari multiple outputs\n",
    "with tf.GradientTape(persistent=True) as tape:\n",
    "    z1 = f(w1, w2 + 2.)\n",
    "    z2 = f(w1, w2 + 5.)\n",
    "    z3 = f(w1, w2 + 7.)\n",
    "\n",
    "# Gradien total adalah jumlah gradien individu\n",
    "total_gradients = tf.reduce_sum(tf.stack([tape.gradient(z, [w1, w2]) for z in (z1, z2, z3)]), axis=0)\n",
    "print(\"\\nGradien total dari [z1, z2, z3] terhadap [w1, w2]:\\n\", total_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "eba60c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tape # Penting untuk menghapus tape persistent setelah digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "ad12189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Jacobians:\n",
      " [<tf.Tensor: shape=(), dtype=float32, numpy=36.0>, <tf.Tensor: shape=(), dtype=float32, numpy=10.0>]\n",
      "Hessians:\n",
      " [[<tf.Tensor: shape=(), dtype=float32, numpy=6.0>, <tf.Tensor: shape=(), dtype=float32, numpy=2.0>], [<tf.Tensor: shape=(), dtype=float32, numpy=2.0>, None]]\n"
     ]
    }
   ],
   "source": [
    "# Hessian (turunan kedua)\n",
    "w1, w2 = tf.Variable(5.), tf.Variable(3.) # Reset variabel\n",
    "with tf.GradientTape(persistent=True) as hessian_tape:\n",
    "    with tf.GradientTape() as jacobian_tape:\n",
    "        z = f(w1, w2)\n",
    "    jacobians = jacobian_tape.gradient(z, [w1, w2])\n",
    "hessians = [hessian_tape.gradient(jacobian, [w1, w2])\n",
    "            for jacobian in jacobians]\n",
    "del hessian_tape\n",
    "print(\"\\nJacobians:\\n\", jacobians)\n",
    "print(\"Hessians:\\n\", hessians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "84a254d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien dengan tf.stop_gradient (w2 tidak berkontribusi):\n",
      " [<tf.Tensor: shape=(), dtype=float32, numpy=30.0>, None]\n"
     ]
    }
   ],
   "source": [
    "# tf.stop_gradient\n",
    "def f_stop_gradient(w1, w2):\n",
    "    return 3 * w1 ** 2 + tf.stop_gradient(2 * w1 * w2) # w2 tidak akan berkontribusi pada gradien\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    z_sg = f_stop_gradient(w1, w2)\n",
    "print(\"\\nGradien dengan tf.stop_gradient (w2 tidak berkontribusi):\\n\", tape.gradient(z_sg, [w1, w2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "12d143cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gradien my_softplus pada x=100 (akan mendekati 1):\n",
      " [<tf.Tensor: shape=(), dtype=float32, numpy=nan>]\n"
     ]
    }
   ],
   "source": [
    "# Mengatasi gradien yang tidak stabil (contoh my_softplus)\n",
    "def my_softplus(x):\n",
    "    return tf.math.log(tf.exp(x) + 1.)\n",
    "\n",
    "x = tf.Variable(100.)\n",
    "with tf.GradientTape() as tape:\n",
    "    z = my_softplus(x)\n",
    "print(\"\\nGradien my_softplus pada x=100 (akan mendekati 1):\\n\", tape.gradient(z, [x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "410aef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output dan gradien my_better_softplus pada x=1000:\n",
      " tf.Tensor([1000.], shape=(1,), dtype=float32) [<tf.Tensor: shape=(1,), dtype=float32, numpy=array([nan], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "# my_better_softplus untuk stabilitas numerik\n",
    "@tf.function\n",
    "def my_better_softplus(z):\n",
    "    # Mengatasi masalah numerik untuk z yang sangat besar\n",
    "    return tf.where(z > 30., z, tf.math.log(tf.exp(z) + 1.))\n",
    "\n",
    "x_large = tf.Variable([1000.])\n",
    "with tf.GradientTape() as tape:\n",
    "    z_better = my_better_softplus(x_large)\n",
    "print(\"\\nOutput dan gradien my_better_softplus pada x=1000:\\n\", z_better, tape.gradient(z_better, [x_large]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020025aa",
   "metadata": {},
   "source": [
    "#### Custom Training Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "4b4326ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat *custom training loop* tanpa menggunakan `model.fit()`.\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ab3b0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l2_reg = keras.regularizers.l2(0.05)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"elu\", kernel_initializer=\"he_normal\", kernel_regularizer=l2_reg),\n",
    "    keras.layers.Dense(1, kernel_regularizer=l2_reg)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "0b170d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_batch(X, y, batch_size=32):\n",
    "    \"\"\"Membangkitkan batch acak dari data.\"\"\"\n",
    "    idx = np.random.randint(len(X), size=batch_size)\n",
    "    return X[idx], y[idx]\n",
    "    \n",
    "def print_status_bar(iteration, total, loss, metrics=None, size=30):\n",
    "    \"\"\"Fungsi untuk menampilkan status bar pelatihan.\"\"\"\n",
    "    metrics = \" - \".join([f\"{m.name}: {m.result():.4f}\" for m in [loss] + (metrics or [])])\n",
    "    end = \"\" if iteration < total else \"\\n\"\n",
    "    p = (size - 1) * iteration // total\n",
    "    bar = \"=\" * p + \">\" + \".\" * (size - p - 1) if iteration < total else \"=\" * size\n",
    "    fmt = f\"\\r{iteration}/{total} [{bar}] - {metrics}\"\n",
    "    print(fmt, end=end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "68eadeb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Contoh print_status_bar:\n",
      "10/10 [==============================] - loss: 0.2929 - mean_square: 38.5000\n"
     ]
    }
   ],
   "source": [
    "# Contoh penggunaan print_status_bar\n",
    "print(\"\\nContoh print_status_bar:\")\n",
    "mean_loss = keras.metrics.Mean(name=\"loss\")\n",
    "mean_square = keras.metrics.Mean(name=\"mean_square\")\n",
    "for i in range(1, 11): # Mengurangi iterasi untuk contoh\n",
    "    loss = 1 / i\n",
    "    mean_loss(loss)\n",
    "    mean_square(i ** 2)\n",
    "    print_status_bar(i, 10, mean_loss, [mean_square])\n",
    "    time.sleep(0.01) # Kurangi sleep time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "9af043b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom training loop utama\n",
    "n_epochs = 4\n",
    "batch_size = 32\n",
    "n_steps = len(X_train) // batch_size\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.MeanSquaredError()\n",
    "mean_loss = keras.metrics.Mean(name=\"train_loss\") # Beri nama untuk kejelasan\n",
    "metrics = [keras.metrics.MeanAbsoluteError(name=\"train_mae\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "93ec102d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai Custom Training Loop:\n",
      "Epoch 1/4\n",
      "11610/11610 [==============================] - train_loss: 1.3938 - train_mae: 0.5739\n",
      "Epoch 2/4\n",
      "11610/11610 [==============================] - train_loss: 0.6758 - train_mae: 0.5264\n",
      "Epoch 3/4\n",
      "11610/11610 [==============================] - train_loss: 0.6287 - train_mae: 0.5151\n",
      "Epoch 4/4\n",
      "11610/11610 [==============================] - train_loss: 0.6351 - train_mae: 0.5163\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMemulai Custom Training Loop:\")\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    print(f\"Epoch {epoch}/{n_epochs}\")\n",
    "    for step in range(1, n_steps + 1):\n",
    "        X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch, training=True) # Pastikan training=True\n",
    "            main_loss = loss_fn(y_batch, y_pred)\n",
    "            loss = tf.add_n([main_loss] + model.losses) # Tambahkan loss regularisasi\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        for var in model.variables:\n",
    "            if var.constraint is not None:\n",
    "                var.assign(var.constraint(var))\n",
    "        mean_loss(loss)\n",
    "        for metric in metrics:\n",
    "            metric(y_batch, y_pred)\n",
    "        print_status_bar(step * batch_size, len(y_train), mean_loss, metrics)\n",
    "    print_status_bar(len(y_train), len(y_train), mean_loss, metrics) # Cetak bar terakhir\n",
    "    for metric in [mean_loss] + metrics:\n",
    "        metric.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "aac6e883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memulai Custom Training Loop dengan TQDM (jika terinstal):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/4: 100%|██████████| 362/362 [00:33<00:00, 10.87it/s, loss=0.642, train_mae=0.521]\n",
      "Epoch 2/4: 100%|██████████| 362/362 [00:37<00:00,  9.69it/s, loss=0.648, train_mae=0.522]\n",
      "Epoch 3/4: 100%|██████████| 362/362 [00:33<00:00, 10.89it/s, loss=0.631, train_mae=0.513]\n",
      "Epoch 4/4: 100%|██████████| 362/362 [00:48<00:00,  7.51it/s, loss=0.627, train_mae=0.51]\n",
      "Semua epoch: 100%|██████████| 4/4 [02:32<00:00, 38.03s/it]\n"
     ]
    }
   ],
   "source": [
    "# TQDM\n",
    "try:\n",
    "    from tqdm import trange\n",
    "except ImportError:\n",
    "    trange = None\n",
    "    \n",
    "print(\"\\nMemulai Custom Training Loop dengan TQDM (jika terinstal):\")\n",
    "if trange is not None:\n",
    "    with trange(1, n_epochs + 1, desc=\"Semua epoch\") as epochs:\n",
    "        for epoch in epochs:\n",
    "            with trange(1, n_steps + 1, desc=f\"Epoch {epoch}/{n_epochs}\") as steps:\n",
    "                for step in steps:\n",
    "                    X_batch, y_batch = random_batch(X_train_scaled, y_train)\n",
    "                    with tf.GradientTape() as tape:\n",
    "                        y_pred = model(X_batch, training=True)\n",
    "                        main_loss = loss_fn(y_batch, y_pred)\n",
    "                        loss = tf.add_n([main_loss] + model.losses)\n",
    "                    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "                    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "                    for var in model.variables:\n",
    "                        if var.constraint is not None:\n",
    "                            var.assign(var.constraint(var))\n",
    "                    mean_loss(loss)\n",
    "                    status = OrderedDict()\n",
    "                    status[\"loss\"] = mean_loss.result().numpy()\n",
    "                    for metric in metrics:\n",
    "                        metric(y_batch, y_pred)\n",
    "                        status[metric.name] = metric.result().numpy()\n",
    "                    steps.set_postfix(status)\n",
    "            for metric in [mean_loss] + metrics:\n",
    "                metric.reset_state()\n",
    "else:\n",
    "    print(\"Untuk menjalankan sel ini, silakan instal tqdm, ipywidgets dan mulai ulang Jupyter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ca22a",
   "metadata": {},
   "source": [
    "### 4. TensorFlow Functions and Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "b341aca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output cube(2): 8\n",
      "Output cube(tf.constant(2.0)): tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Menggunakan `tf.function` untuk kompilasi grafik dan optimasi.\n",
    "def cube(x):\n",
    "    \"\"\"Fungsi Python biasa.\"\"\"\n",
    "    return x ** 3\n",
    "\n",
    "print(\"\\nOutput cube(2):\", cube(2))\n",
    "print(\"Output cube(tf.constant(2.0)):\", cube(tf.constant(2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "e847df7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Objek tf_cube (tf.function): <tensorflow.python.eager.polymorphic_function.polymorphic_function.Function object at 0x7f4a3064a780>\n",
      "Output tf_cube(2): 8\n",
      "Output tf_cube(tf.constant(2.0)): tf.Tensor(8.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf_cube = tf.function(cube)\n",
    "print(\"\\nObjek tf_cube (tf.function):\", tf_cube)\n",
    "print(\"Output tf_cube(2):\", tf_cube(2))\n",
    "print(\"Output tf_cube(tf.constant(2.0)):\", tf_cube(tf.constant(2.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7025fca6",
   "metadata": {},
   "source": [
    "##### TF Functions dan Concrete Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "d76e9c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Concrete function graph:\n",
      " FuncGraph(name=cube, id=139955154941760)\n",
      "Output concrete_function(tf.constant(2.0)): tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "Apakah concrete_function sama dengan tf_cube.get_concrete_function(tf.constant(2.0))? True\n"
     ]
    }
   ],
   "source": [
    "concrete_function = tf_cube.get_concrete_function(tf.constant(2.0))\n",
    "print(\"\\nConcrete function graph:\\n\", concrete_function.graph)\n",
    "print(\"Output concrete_function(tf.constant(2.0)):\", concrete_function(tf.constant(2.0)))\n",
    "print(\"Apakah concrete_function sama dengan tf_cube.get_concrete_function(tf.constant(2.0))?\",\n",
    "      concrete_function is tf_cube.get_concrete_function(tf.constant(2.0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818191f",
   "metadata": {},
   "source": [
    "##### Mengeksplorasi Definisi Fungsi dan Grafik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "273cfc79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operasi dalam graph:\n",
      " [<tf.Operation 'x' type=Placeholder>, <tf.Operation 'pow/y' type=Const>, <tf.Operation 'pow' type=Pow>, <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "ops = concrete_function.graph.get_operations()\n",
    "print(\"\\nOperasi dalam graph:\\n\", ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "5a839217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input operasi 'pow':\n",
      " [<tf.Tensor 'x:0' shape=() dtype=float32>, <tf.Tensor 'pow/y:0' shape=() dtype=float32>]\n",
      "Output operasi 'pow':\n",
      " [<tf.Tensor 'pow:0' shape=() dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "pow_op = ops[2] # Cari operasi power\n",
    "print(\"\\nInput operasi 'pow':\\n\", list(pow_op.inputs))\n",
    "print(\"Output operasi 'pow':\\n\", pow_op.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "0f939057",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = None\n",
    "output_tensor = None\n",
    "for op in ops:\n",
    "    if op.name.startswith(\"x\") and op.type == \"Placeholder\": # Contoh mencari placeholder input\n",
    "        input_tensor = op.outputs[0]\n",
    "    elif op.name.startswith(\"Identity\"): # Mencari tensor output\n",
    "        output_tensor = op.outputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "89d71a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input tensor:\n",
      " Tensor(\"x:0\", shape=(), dtype=float32)\n",
      "Output tensor:\n",
      " Tensor(\"Identity:0\", shape=(), dtype=float32)\n",
      "\n",
      "Tanda tangan fungsi (function_def.signature):\n",
      " name: \"__inference_cube_16819182\"\n",
      "input_arg {\n",
      "  name: \"x\"\n",
      "  type: DT_FLOAT\n",
      "}\n",
      "output_arg {\n",
      "  name: \"identity\"\n",
      "  type: DT_FLOAT\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_tensor = next((op.outputs[0] for op in ops if op.type == \"Placeholder\"), None)\n",
    "output_tensor = next((op.outputs[0] for op in ops if op.type == \"Identity\"), None)\n",
    "\n",
    "if input_tensor is not None:\n",
    "    print(\"\\nInput tensor:\\n\", input_tensor)\n",
    "else:\n",
    "    print(\"\\nTidak dapat menemukan input tensor.\")\n",
    "\n",
    "if output_tensor is not None:\n",
    "    print(\"Output tensor:\\n\", output_tensor)\n",
    "else:\n",
    "    print(\"Tidak dapat menemukan output tensor.\")\n",
    "\n",
    "print(\"\\nTanda tangan fungsi (function_def.signature):\\n\", concrete_function.function_def.signature)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0975d0",
   "metadata": {},
   "source": [
    "##### Bagaimana TF Functions Melacak Fungsi Python untuk Mengekstrak Grafik Komputasinya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "08ac66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def tf_cube_tracing(x):\n",
    "    print(\"print (akan hanya dipanggil saat tracing):\", x)\n",
    "    return x ** 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "d94ade7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tracing tf_cube_tracing:\n",
      "print (akan hanya dipanggil saat tracing): tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "Hasil pertama: tf.Tensor(8.0, shape=(), dtype=float32)\n",
      "print (akan hanya dipanggil saat tracing): 2\n",
      "Hasil kedua (reuse graph): 8\n",
      "print (akan hanya dipanggil saat tracing): 3\n",
      "Hasil ketiga (reuse graph): 27\n",
      "print (akan hanya dipanggil saat tracing): tf.Tensor([[1. 2.]], shape=(1, 2), dtype=float32)\n",
      "Hasil keempat (tracing baru): tf.Tensor([[1. 8.]], shape=(1, 2), dtype=float32)\n",
      "print (akan hanya dipanggil saat tracing): tf.Tensor(\n",
      "[[3. 4.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n",
      "Hasil kelima (tracing baru): tf.Tensor(\n",
      "[[ 27.  64.]\n",
      " [125. 216.]], shape=(2, 2), dtype=float32)\n",
      "print (akan hanya dipanggil saat tracing): tf.Tensor(\n",
      "[[ 7.  8.]\n",
      " [ 9. 10.]\n",
      " [11. 12.]], shape=(3, 2), dtype=float32)\n",
      "Hasil keenam (tracing baru): tf.Tensor(\n",
      "[[ 343.  512.]\n",
      " [ 729. 1000.]\n",
      " [1331. 1728.]], shape=(3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTracing tf_cube_tracing:\")\n",
    "result = tf_cube_tracing(tf.constant(2.0))\n",
    "print(\"Hasil pertama:\", result)\n",
    "result = tf_cube_tracing(2)\n",
    "print(\"Hasil kedua (reuse graph):\", result)\n",
    "result = tf_cube_tracing(3)\n",
    "print(\"Hasil ketiga (reuse graph):\", result)\n",
    "result = tf_cube_tracing(tf.constant([[1., 2.]])) # Bentuk baru: tracing lagi!\n",
    "print(\"Hasil keempat (tracing baru):\", result)\n",
    "result = tf_cube_tracing(tf.constant([[3., 4.], [5., 6.]])) # Bentuk baru: tracing lagi!\n",
    "print(\"Hasil kelima (tracing baru):\", result)\n",
    "result = tf_cube_tracing(tf.constant([[7., 8.], [9., 10.], [11., 12.]])) # Bentuk baru: tracing lagi!\n",
    "print(\"Hasil keenam (tracing baru):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "0a7373aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menentukan signature input secara eksplisit\n",
    "@tf.function(input_signature=[tf.TensorSpec([None, 28, 28], tf.float32)])\n",
    "def shrink(images):\n",
    "    print(\"Tracing (dengan input_signature):\", images)\n",
    "    return images[:, ::2, ::2] # Menghilangkan setengah baris dan kolom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "4039b06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8866b0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memanggil shrink dengan batch_1:\n",
      "Tracing (dengan input_signature): tf.Tensor(\n",
      "[[[0.6645621  0.44100678 0.3528825  ... 0.33695042 0.60141766 0.21062577]\n",
      "  [0.8527372  0.44062173 0.9485276  ... 0.7223145  0.32347047 0.82577336]\n",
      "  [0.4976915  0.19483674 0.7588748  ... 0.29590535 0.9356605  0.1341263 ]\n",
      "  ...\n",
      "  [0.2561208  0.8307164  0.87797034 ... 0.0678556  0.33755875 0.2586832 ]\n",
      "  [0.31682265 0.12932086 0.6521549  ... 0.89806473 0.647637   0.7253767 ]\n",
      "  [0.4288993  0.24039364 0.80511487 ... 0.24294508 0.9748163  0.6613418 ]]\n",
      "\n",
      " [[0.77894723 0.4067055  0.73151565 ... 0.24318087 0.23610544 0.15391183]\n",
      "  [0.54378176 0.45701122 0.30383396 ... 0.05334079 0.69346654 0.35220075]\n",
      "  [0.0724014  0.9927635  0.5087143  ... 0.07345116 0.21799457 0.4217304 ]\n",
      "  ...\n",
      "  [0.4478116  0.76988566 0.740152   ... 0.71009946 0.59767795 0.7616435 ]\n",
      "  [0.46121967 0.79486585 0.78757036 ... 0.53236294 0.22297502 0.5570046 ]\n",
      "  [0.33492267 0.1064204  0.48111653 ... 0.22867358 0.28147495 0.24379838]]\n",
      "\n",
      " [[0.5862695  0.4526795  0.7455579  ... 0.06854057 0.16669679 0.16796172]\n",
      "  [0.31265163 0.31538332 0.5703062  ... 0.05731499 0.04252112 0.41597903]\n",
      "  [0.120875   0.86303496 0.7596128  ... 0.69320047 0.5747273  0.45209718]\n",
      "  ...\n",
      "  [0.42558515 0.03289342 0.5577935  ... 0.25871873 0.18495238 0.5835978 ]\n",
      "  [0.81739044 0.97014    0.38885367 ... 0.00345445 0.09342504 0.53514254]\n",
      "  [0.3433907  0.20302999 0.10585749 ... 0.4945904  0.84568083 0.83324707]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.5475807  0.9436978  0.36464083 ... 0.1706729  0.91412926 0.2252326 ]\n",
      "  [0.11780798 0.0930773  0.21050417 ... 0.7203454  0.14950359 0.09019756]\n",
      "  [0.68676436 0.72990143 0.7293551  ... 0.33131194 0.7235246  0.38036656]\n",
      "  ...\n",
      "  [0.94448006 0.6391833  0.62387455 ... 0.23730016 0.28017545 0.77261126]\n",
      "  [0.8633226  0.3217007  0.05088627 ... 0.20586228 0.4446349  0.15099156]\n",
      "  [0.02297056 0.22511041 0.22982585 ... 0.8841504  0.5134437  0.34773302]]\n",
      "\n",
      " [[0.53471744 0.14776564 0.1431961  ... 0.34951305 0.71379495 0.6666759 ]\n",
      "  [0.96630347 0.5483531  0.89369583 ... 0.35442257 0.08529437 0.96870434]\n",
      "  [0.01154852 0.83721495 0.72411025 ... 0.5451002  0.8742863  0.66677284]\n",
      "  ...\n",
      "  [0.23431063 0.2929201  0.2151469  ... 0.21087396 0.55509305 0.72544134]\n",
      "  [0.09107018 0.44434214 0.3173617  ... 0.9204478  0.8911501  0.46300268]\n",
      "  [0.14981008 0.5767188  0.63979113 ... 0.12596846 0.6390257  0.00315058]]\n",
      "\n",
      " [[0.27489865 0.49021447 0.49451184 ... 0.21276486 0.6065593  0.14953113]\n",
      "  [0.6484107  0.71785736 0.96093214 ... 0.49525607 0.84952354 0.67734444]\n",
      "  [0.78476393 0.7225429  0.98253345 ... 0.6314111  0.15450263 0.04216361]\n",
      "  ...\n",
      "  [0.25054204 0.10908854 0.38010812 ... 0.28649056 0.07205057 0.956885  ]\n",
      "  [0.3296739  0.550683   0.43933952 ... 0.9141507  0.9317205  0.82207   ]\n",
      "  [0.5799694  0.5143572  0.8685831  ... 0.58219016 0.905087   0.34470034]]], shape=(100, 28, 28), dtype=float32)\n",
      "Memanggil shrink dengan batch_2:\n",
      "Tracing (dengan input_signature): tf.Tensor(\n",
      "[[[6.87891245e-01 4.84478831e-01 9.30994391e-01 ... 5.97084761e-01\n",
      "   6.10948205e-01 8.20862651e-01]\n",
      "  [8.32697868e-01 8.91584873e-01 1.37722492e-02 ... 6.82271838e-01\n",
      "   1.81088686e-01 8.16348076e-01]\n",
      "  [6.56516552e-01 9.25825596e-01 2.39171505e-01 ... 8.59481573e-01\n",
      "   9.16732788e-01 5.04495382e-01]\n",
      "  ...\n",
      "  [4.86654401e-01 7.09324479e-01 4.22688365e-01 ... 3.37955713e-01\n",
      "   8.98083329e-01 7.75284886e-01]\n",
      "  [7.56240726e-01 3.86423945e-01 9.84934568e-02 ... 9.67101097e-01\n",
      "   5.45385957e-01 3.94003034e-01]\n",
      "  [5.13827801e-02 4.37925696e-01 5.11755347e-01 ... 4.16999817e-01\n",
      "   6.65369272e-01 3.10323596e-01]]\n",
      "\n",
      " [[4.68095303e-01 4.83134031e-01 8.93115640e-01 ... 6.52149796e-01\n",
      "   4.83266115e-01 3.12156677e-01]\n",
      "  [3.18888783e-01 5.48168421e-01 3.84578109e-01 ... 1.13902330e-01\n",
      "   6.10907793e-01 2.45503426e-01]\n",
      "  [1.21726632e-01 6.38098001e-01 5.02948761e-02 ... 5.76655865e-02\n",
      "   5.90493798e-01 5.28792858e-01]\n",
      "  ...\n",
      "  [6.36515141e-01 3.40405822e-01 9.53040600e-01 ... 1.56382680e-01\n",
      "   6.93416238e-01 2.10728288e-01]\n",
      "  [7.40113378e-01 3.47735286e-01 4.73274112e-01 ... 7.01130509e-01\n",
      "   3.13963890e-01 4.29579735e-01]\n",
      "  [6.59167647e-01 5.85359335e-02 9.36100721e-01 ... 5.21889687e-01\n",
      "   5.05070686e-02 7.95936584e-03]]\n",
      "\n",
      " [[3.88257146e-01 7.54001141e-02 1.53043985e-01 ... 8.94077778e-01\n",
      "   2.20760584e-01 6.99489236e-01]\n",
      "  [4.38159943e-01 3.13357115e-02 4.69766855e-01 ... 2.73404598e-01\n",
      "   3.83234262e-01 2.72206068e-02]\n",
      "  [8.50003123e-01 6.09340549e-01 3.31544876e-02 ... 2.70872116e-01\n",
      "   6.19746804e-01 4.53340769e-01]\n",
      "  ...\n",
      "  [6.53539181e-01 4.90873694e-01 8.05114150e-01 ... 3.69842410e-01\n",
      "   2.15502024e-01 7.04809427e-01]\n",
      "  [5.57104349e-01 1.61752462e-01 2.38811016e-01 ... 3.94996405e-02\n",
      "   8.97540212e-01 6.37976766e-01]\n",
      "  [3.07789564e-01 5.27334571e-01 7.46238708e-01 ... 2.43307352e-01\n",
      "   4.23223615e-01 6.18501902e-02]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[9.66778040e-01 8.00511718e-01 4.43431854e-01 ... 3.99732590e-02\n",
      "   3.79722834e-01 6.77461624e-01]\n",
      "  [1.16179705e-01 3.75347376e-01 1.88602686e-01 ... 4.06266928e-01\n",
      "   3.49336982e-01 2.77695656e-01]\n",
      "  [6.35783195e-01 9.45858955e-01 1.67649508e-01 ... 6.46845818e-01\n",
      "   6.76064491e-01 5.86586714e-01]\n",
      "  ...\n",
      "  [7.20577717e-01 4.50257063e-02 7.53470063e-01 ... 2.77552009e-01\n",
      "   4.61938381e-02 4.18333888e-01]\n",
      "  [4.25655365e-01 9.84833360e-01 8.05940628e-02 ... 8.22386146e-01\n",
      "   7.99716353e-01 8.11392665e-01]\n",
      "  [5.35297513e-01 4.77250338e-01 1.46151662e-01 ... 5.04772425e-01\n",
      "   4.50155854e-01 1.93210483e-01]]\n",
      "\n",
      " [[7.29301929e-01 3.37142467e-01 9.51626778e-01 ... 8.23777676e-01\n",
      "   3.89971972e-01 2.33695865e-01]\n",
      "  [4.83384848e-01 1.09528184e-01 8.16575170e-01 ... 2.76557922e-01\n",
      "   3.81363988e-01 6.68007970e-01]\n",
      "  [1.81701183e-02 2.99708843e-02 3.75454783e-01 ... 7.12298155e-02\n",
      "   8.88272047e-01 4.48618054e-01]\n",
      "  ...\n",
      "  [9.75306988e-01 1.84200525e-01 4.17941689e-01 ... 2.07675815e-01\n",
      "   9.26910520e-01 9.98531580e-02]\n",
      "  [1.09529495e-03 1.64198518e-01 1.12329721e-01 ... 1.52245402e-01\n",
      "   3.36061478e-01 5.79725504e-02]\n",
      "  [9.56850648e-01 6.43746972e-01 2.84469366e-01 ... 4.39015508e-01\n",
      "   2.14121938e-01 9.58594322e-01]]\n",
      "\n",
      " [[3.01942229e-01 2.73497939e-01 3.71559620e-01 ... 7.74389505e-01\n",
      "   8.04347157e-01 3.96964312e-01]\n",
      "  [5.55836320e-01 7.39310622e-01 9.88241434e-01 ... 6.54317975e-01\n",
      "   6.81649446e-02 6.66495442e-01]\n",
      "  [1.93042397e-01 5.61495066e-01 4.22754526e-01 ... 3.44984055e-01\n",
      "   1.16777420e-01 9.73059893e-01]\n",
      "  ...\n",
      "  [3.46712470e-01 1.74522400e-04 1.07247710e-01 ... 8.39855552e-01\n",
      "   1.41772389e-01 7.35432863e-01]\n",
      "  [1.52983189e-01 8.35504651e-01 9.04349446e-01 ... 5.09295106e-01\n",
      "   7.23227024e-01 9.41125870e-01]\n",
      "  [7.57812142e-01 8.83400798e-01 9.10782337e-01 ... 2.96651483e-01\n",
      "   5.03049731e-01 6.18115783e-01]]], shape=(50, 28, 28), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_1 = tf.random.uniform(shape=[100, 28, 28])\n",
    "img_batch_2 = tf.random.uniform(shape=[50, 28, 28])\n",
    "print(\"\\nMemanggil shrink dengan batch_1:\")\n",
    "preprocessed_images = shrink(img_batch_1) # Traces the function.\n",
    "print(\"Memanggil shrink dengan batch_2:\")\n",
    "preprocessed_images = shrink(img_batch_2) # Menggunakan kembali concrete function yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "e6a2f20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Memanggil shrink dengan batch_3 (akan error karena shape tidak cocok):\n",
      "Tracing (dengan input_signature): tf.Tensor(\n",
      "[[[0.7413678  0.62854624]\n",
      "  [0.01738465 0.3431449 ]]\n",
      "\n",
      " [[0.51063764 0.3777541 ]\n",
      "  [0.07321596 0.02137029]]], shape=(2, 2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "img_batch_3 = tf.random.uniform(shape=[2, 2, 2])\n",
    "try:\n",
    "    print(\"\\nMemanggil shrink dengan batch_3 (akan error karena shape tidak cocok):\")\n",
    "    preprocessed_images = shrink(img_batch_3)  # Menolak tipe atau bentuk yang tidak diharapkan\n",
    "except ValueError as ex:\n",
    "    print(\"Error:\", ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64463764",
   "metadata": {},
   "source": [
    "#### Menggunakan Autograph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "da8c0f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output add_10_static(tf.constant(5)): None\n",
      "Operasi dalam graph add_10_static:\n",
      " [<tf.Operation 'x' type=Placeholder>, <tf.Operation 'add/y' type=Const>, <tf.Operation 'add' type=AddV2>, <tf.Operation 'add_1/y' type=Const>, <tf.Operation 'add_1' type=AddV2>, <tf.Operation 'add_2/y' type=Const>, <tf.Operation 'add_2' type=AddV2>, <tf.Operation 'add_3/y' type=Const>, <tf.Operation 'add_3' type=AddV2>, <tf.Operation 'add_4/y' type=Const>, <tf.Operation 'add_4' type=AddV2>, <tf.Operation 'add_5/y' type=Const>, <tf.Operation 'add_5' type=AddV2>, <tf.Operation 'add_6/y' type=Const>, <tf.Operation 'add_6' type=AddV2>, <tf.Operation 'add_7/y' type=Const>, <tf.Operation 'add_7' type=AddV2>, <tf.Operation 'add_8/y' type=Const>, <tf.Operation 'add_8' type=AddV2>, <tf.Operation 'add_9/y' type=Const>, <tf.Operation 'add_9' type=AddV2>]\n"
     ]
    }
   ],
   "source": [
    "# \"Static\" for loop menggunakan range()\n",
    "@tf.function\n",
    "def add_10_static(x):\n",
    "    for i in range(10):\n",
    "        x += 1\n",
    "    return \n",
    "    \n",
    "print(\"\\nOutput add_10_static(tf.constant(5)):\", add_10_static(tf.constant(5)))\n",
    "print(\"Operasi dalam graph add_10_static:\\n\", add_10_static.get_concrete_function(tf.constant(5)).graph.get_operations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "4f768bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output add_10_dynamic_while(tf.constant(5)): tf.Tensor(15, shape=(), dtype=int32)\n",
      "Operasi dalam graph add_10_dynamic_while:\n",
      " [<tf.Operation 'x' type=Placeholder>, <tf.Operation 'Const' type=Const>, <tf.Operation 'while/maximum_iterations' type=Const>, <tf.Operation 'while/loop_counter' type=Const>, <tf.Operation 'while' type=StatelessWhile>, <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "# \"Dynamic\" loop menggunakan tf.while_loop()\n",
    "@tf.function\n",
    "def add_10_dynamic_while(x):\n",
    "    condition = lambda i, x_val: tf.less(i, 10)\n",
    "    body = lambda i, x_val: (tf.add(i, 1), tf.add(x_val, 1))\n",
    "    final_i, final_x = tf.while_loop(condition, body, [tf.constant(0), x])\n",
    "    return final_x\n",
    "\n",
    "print(\"\\nOutput add_10_dynamic_while(tf.constant(5)):\", add_10_dynamic_while(tf.constant(5)))\n",
    "print(\"Operasi dalam graph add_10_dynamic_while:\\n\", add_10_dynamic_while.get_concrete_function(tf.constant(5)).graph.get_operations())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "cfcc51bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output add_10_dynamic_range(tf.constant(5)): tf.Tensor(15, shape=(), dtype=int32)\n",
      "Operasi dalam graph add_10_dynamic_range:\n",
      " [<tf.Operation 'x' type=Placeholder>, <tf.Operation 'range/start' type=Const>, <tf.Operation 'range/limit' type=Const>, <tf.Operation 'range/delta' type=Const>, <tf.Operation 'range' type=Range>, <tf.Operation 'sub' type=Sub>, <tf.Operation 'floordiv' type=FloorDiv>, <tf.Operation 'mod' type=FloorMod>, <tf.Operation 'zeros_like' type=Const>, <tf.Operation 'NotEqual' type=NotEqual>, <tf.Operation 'Cast' type=Cast>, <tf.Operation 'add' type=AddV2>, <tf.Operation 'zeros_like_1' type=Const>, <tf.Operation 'Maximum' type=Maximum>, <tf.Operation 'while/maximum_iterations' type=Const>, <tf.Operation 'while/loop_counter' type=Const>, <tf.Operation 'while' type=StatelessWhile>, <tf.Operation 'Identity' type=Identity>]\n"
     ]
    }
   ],
   "source": [
    "# \"Dynamic\" for loop menggunakan tf.range() (ditangkap oleh autograph)\n",
    "@tf.function\n",
    "def add_10_dynamic_range(x):\n",
    "    for i in tf.range(10):\n",
    "        x = x + 1\n",
    "    return x\n",
    "\n",
    "print(\"\\nOutput add_10_dynamic_range(tf.constant(5)):\", add_10_dynamic_range(tf.constant(5)))\n",
    "print(\"Operasi dalam graph add_10_dynamic_range:\\n\", add_10_dynamic_range.get_concrete_function(tf.constant(0)).graph.get_operations())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0200f792",
   "metadata": {},
   "source": [
    "# Penjelasan\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Fungsi Loss Kustom\n",
    "\n",
    "**Tujuan**: Mendemonstrasikan pembuatan dan penggunaan fungsi loss kustom.\n",
    "\n",
    "**Hasil**:\n",
    "- Fungsi `huber_fn` berhasil dibuat dan digunakan untuk melatih model.\n",
    "- Setelah 4 epoch (2 sebelum simpan, 2 setelah muat), model mencapai:\n",
    "  - `val_loss` ≈ 0.1856\n",
    "  - `val_mae` ≈ 0.4598\n",
    "- Model berhasil disimpan dan dimuat ulang dengan `custom_objects`.\n",
    "- Class `HuberLoss` berhasil dibuat dengan dekorator `@register_keras_serializable`, memungkinkan penyimpanan dan pemuatan tanpa `custom_objects`.\n",
    "  - Performa sebanding, `val_mae` ≈ 0.4858 setelah 4 epoch.\n",
    "\n",
    "**Kesimpulan**: Menggunakan subclass dari `keras.losses.Loss` dengan dekorator adalah praktik terbaik untuk portabilitas.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Komponen Kustom Lainnya (Aktivasi, Initializer, dll.)\n",
    "\n",
    "**Tujuan**: Menunjukkan pembuatan dan integrasi berbagai komponen layer kustom.\n",
    "\n",
    "**Hasil**:\n",
    "- Model berhasil dilatih dengan:\n",
    "  - `my_softplus` (aktivasi)\n",
    "  - `MyGlorotInitializer`\n",
    "  - `MyL1Regularizer`\n",
    "  - `MyPositiveWeights` (constraint)\n",
    "- Performa: `val_mae` ≈ 0.5067 setelah 2 epoch.\n",
    "\n",
    "**Kesimpulan**: Keras fleksibel dan mendukung hampir semua komponen layer kustom asalkan di-serialisasi dengan benar.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Metrik Kustom\n",
    "\n",
    "**Tujuan**: Menunjukkan pembuatan metrik kustom, termasuk metrik stateful.\n",
    "\n",
    "**Hasil**:\n",
    "- `create_huber` sebagai fungsi metrik menunjukkan perbedaan antara loss berbobot dan metrik tidak berbobot.\n",
    "- `HuberMetric` sebagai subclass dari `keras.metrics.Metric` berhasil mengakumulasi nilai secara streaming.\n",
    "- Versi sederhana dengan subclass dari `keras.metrics.Mean` juga efektif.\n",
    "\n",
    "**Kesimpulan**: Untuk metrik sederhana gunakan fungsi. Untuk metrik streaming gunakan class dengan state internal.\n",
    "\n",
    "---\n",
    "\n",
    "## 4. Layer Kustom\n",
    "\n",
    "**Tujuan**: Menunjukkan pembuatan berbagai jenis layer kustom.\n",
    "\n",
    "**Hasil**:\n",
    "- `keras.layers.Lambda`: membuat layer eksponensial sederhana.\n",
    "- `MyDense`: layer stateful mirip `Dense`, loss evaluasi ≈ 0.4058.\n",
    "- `MyMultiLayer`: multi-input dan multi-output dengan Functional API.\n",
    "- `AddGaussianNoise`: layer dengan perilaku berbeda saat training dan inferensi, `loss` meningkat ke 0.7795 → regularisasi bekerja.\n",
    "\n",
    "**Kesimpulan**: Keras menyediakan berbagai tingkat abstraksi layer kustom, memungkinkan arsitektur kompleks.\n",
    "\n",
    "---\n",
    "\n",
    "## 5. Model Kustom\n",
    "\n",
    "**Tujuan**: Menunjukkan pembuatan arsitektur model dengan subclass dari `keras.Model`.\n",
    "\n",
    "**Hasil**:\n",
    "- `ResidualRegressor` dengan skip connection:\n",
    "  - `loss` turun dari 7.26 → 0.5564 setelah 8 epoch.\n",
    "- Alternatif dengan API `Sequential` + `ResidualBlock`, `loss` ≈ 0.9657.\n",
    "\n",
    "**Kesimpulan**: Subclassing memberi kontrol penuh terhadap arsitektur dan proses forward, ideal untuk model kompleks seperti ResNet.\n",
    "\n",
    "---\n",
    "\n",
    "## 6. Loss Berdasarkan Internal Model & Custom Training Loop\n",
    "\n",
    "**Tujuan**: Menunjukkan teknik lanjutan seperti menambahkan loss internal dan loop pelatihan manual.\n",
    "\n",
    "**Hasil**:\n",
    "- `ReconstructingRegressor`: loss tambahan via `self.add_loss()`, metrik `reconstruction_error` terlacak.\n",
    "- Loop pelatihan manual (`tf.GradientTape`) bekerja dengan baik, `train_loss` ≈ 0.6351 setelah 4 epoch.\n",
    "\n",
    "**Kesimpulan**: Custom training loop memberi fleksibilitas penuh untuk eksperimen algoritma non-standar.\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Fungsi TensorFlow dan Graphs\n",
    "\n",
    "**Tujuan**: Mengilustrasikan penggunaan `@tf.function` untuk optimasi kinerja.\n",
    "\n",
    "**Hasil**:\n",
    "- `@tf.function` melakukan tracing satu kali per signature input.\n",
    "- Autograph mengubah flow Python (seperti `for`) menjadi `tf.while_loop`.\n",
    "\n",
    "**Kesimpulan**: `@tf.function` adalah cara standar untuk performa tinggi; pemahaman tracing sangat penting.\n",
    "\n",
    "---\n",
    "\n",
    "📌 *Dokumentasi ini mencerminkan ekosistem Keras yang fleksibel dan kuat, mendukung pemrograman model tingkat lanjut serta komponen kustom yang dapat disimpan dan digunakan ulang.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
